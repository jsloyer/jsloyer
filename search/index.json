[{"content":"Background As a follow on from a previous post I discussed how to enable the IGMP Proxy in the USG product line to permit cross VLAN mDNS traffic. In the UDM/UDM-Pro line its a bit different. There is config.gateway.json file anymore. There are multiple workarounds out there to run Docker containers to add in extra functionality, however this is not one of them.\nIf you are looking to bypass your AT\u0026amp;T gateway then you will need to head down the Docker path, but if you are looking for just Airplay across VLAN\u0026rsquo;s you have arrived at the correct article.\nInstructions If you followed my previous blog post about cross VLAN traffic with Sonos and the USG it talked about how to lock down communications from the IoT VLAN to the data VLAN and allow pinholes through for Sonos. To get things working for Apple Airplay it was actually pretty easy. First you need to make sure you have mDNS turned on. To check this do the following.\nEnable mDNS Goto settings in your controller Goto the services tab on the left Click mDNS at the top Make sure the toggle is set to On Click apply changes Enable multicast enhancement (IGMPv3) Goto settings in your controller Goto Wireless Networks For each of the wireless networks that the Airplay devices are on and your source VLAN (ex data -\u0026gt; IoT) VLAN\u0026rsquo;s you will want to turn on multicast enhancement (IGMPv3). Scroll down the page to find the option for each of your wireless networks. The next step is creating a single firewall rule. The rule that needs to be created is an allow rule that allows established/related traffic to flow from any VLAN. I have this as my base rule and then I add more restrictive rules after that. See below for a screenshot.\nNOTE: You don\u0026rsquo;t have to open things this wide open, you could just create a two rules that allows traffic to flow from the destionation VLAN to the source VLAN and vice versa.\nThis firewall rule should be created in the LAN_IN category.\nNote: As with other allow rules this rule MUST go before your deny rules.\n","date":"2020-08-30T23:24:00-05:00","image":"https://www.jeffsloyer.io/post/apple-airplay-udm/sound_mixer_hu_7c351fccfacb6031.jpg","permalink":"https://www.jeffsloyer.io/post/apple-airplay-udm/","title":"Cross VLAN traffic with a UDM/UDM-Pro and Apple Airplay"},{"content":"Background As a follow on from a previous post I discussed how I locked down VLAN\u0026rsquo;s from a IoT VLAN to my core data VLAN. In that post I described how I got my Sonos speakers and Sonos controller to work over locked down VLAN\u0026rsquo;s. I recently hooked up an old Apple Airport Express and music wouldn\u0026rsquo;t flow when I was on the data VLAN to the IoT VLAN where the Airport Express resided.\nInstructions If you followed my previous blog post it talked about how to lock down communications from the IoT VLAN to the data VLAN and allow pinholes through for Sonos. To get things working for Apple Airplay it was actually pretty easy. First you need to make sure you have mDNS turned on. To check this do the following.\nGoto settings in your controller Goto the services tab on the left Click MDNS at the top Make sure the toggle is set to On Click apply changes The next step is creating a single firewall rule. The rule that needs to be created is an allow rule that allows established/related traffic from your IoT VLAN (the VLAN that your Apple Airplay device is on) to the data VLAN (secure VLAN). See below for a screenshot.\nThis firewall rule should be created in the LAN_IN category.\nNote: As with other allow rules this rule MUST go before your deny rules.\nCredit https://en.community.sonos.com/troubleshooting-228999/multiple-subnets-vlans-and-sonos-workable-clavister-solution-30950\nhttps://community.ubnt.com/t5/UniFi-Routing-Switching/Airplay-across-VLAN-How-to-do/m-p/1966141/highlight/false#M48087\n","date":"2019-04-01T13:24:00-05:00","image":"https://www.jeffsloyer.io/post/apple-airplay-usg/wall_hu_2062b37a696ef10f.jpg","permalink":"https://www.jeffsloyer.io/post/apple-airplay-usg/","title":"Cross VLAN traffic with a USG and Apple Airplay"},{"content":"Background At home I run the 4 port USG router on my Unifi\u0026rsquo;ed network. I have a couple different VLAN\u0026rsquo;s, Data, Management, Security, IoT, and Guest. Each of these networks already has some policies that prevent some of the VLAN\u0026rsquo;s talking to each other. For example I have some firewall rules that prevent my security cameras from talking to the IoT network and talking out to the public Internet. For the past couple months I haven\u0026rsquo;t been running a locked down IoT network. What this means for me is not allowing the IoT VLAN to talk to my Data and Management VLAN\u0026rsquo;s. This is a problem as all of my servers, my iPhone, and laptop are on the Data VLAN. When I turned on a firewall rule to block all traffic to the Data VLAN from the IoT VLAN my Sonos speakers stopped working. After lots of research and trial and error I got things working again. To get things working again you need to run a ICMP Proxy on your USG as well as turn on some additional firewall rules.\nICMP Proxy The ICMP Proxy is probably the most important bit of all of this. The proxy will forward ICMP packets from one VLAN to another. This is crucial in getting Sonos to work on a multi-VLAN setup. For me the following configuration worked, I will walk through what needs to be changed for your setup.\nNotes\nVLAN 2 is my Data VLAN (trusted) VLAN 4 is my IoT VLAN (untrusted) The config below is for a USG 4 Port. If you are running a 3 Port USG change eth0 to eth1. You will need to change the VLAN numbers twice below, for example eth0.2 and eth0.4. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 { \u0026#34;protocols\u0026#34;: { \u0026#34;igmp-proxy\u0026#34;: { \u0026#34;interface\u0026#34;: { \u0026#34;eth0.2\u0026#34;: { \u0026#34;alt-subnet\u0026#34;: [ \u0026#34;0.0.0.0/0\u0026#34; ], \u0026#34;role\u0026#34;: \u0026#34;upstream\u0026#34;, \u0026#34;threshold\u0026#34;: \u0026#34;1\u0026#34; }, \u0026#34;eth0.4\u0026#34;: { \u0026#34;alt-subnet\u0026#34;: [ \u0026#34;0.0.0.0/0\u0026#34; ], \u0026#34;role\u0026#34;: \u0026#34;downstream\u0026#34;, \u0026#34;threshold\u0026#34;: \u0026#34;1\u0026#34; } } } } } The above snippet will need to go on your Unifi Controller. If you are on Linux it is located at /var/lib/unifi/sites\u0026lt;siteid\u0026gt;/config.gateway.json. To get your site id open your web browser and log into your Unifi controller. The site id will be in the url. Make sure you are targheted to the correct site. For example a possible url could be https://10.1.1.1:8443/manage/site/fozvabde/devices/1/50. In this case the site id is fozvabde.\nOnce you have placed your eddited JSON snippet into /var/lib/unifi/sites\u0026lt;siteid\u0026gt;/config.gateway.json login into your controller and navigate to the Devices tab. On that tab select the USG and then click on Config and then Manage Device. Here you will want to click on force provision. Doing this will write the above config.gateway.json file to your USG and then turn on the ICMP Proxy. At this point check to make sure having a Sonos controller on your trusted VLAN can talk to your Sonos Speakers on your untrusted VLAN. If it doesn\u0026rsquo;t work check the config.gateway.json file and make sure you have your interfaces and VLAN\u0026rsquo;s correct. If you can\u0026rsquo;t figure it out leave a comment below.\nFirewall Rules Since we now have things working again we need to break things again. We need to block the traffic from the untrusted VLAN to the trusted VLAN.\nBlock all untrusted traffic I have a group created for my untrusted VLAN\u0026rsquo;s, see below.\nAllow ICMP Traffic Next we need to allow ICMP traffic from your untrusted VLAN to your trusted VLAN. See below. Allow Sonos Traffic Next wee need to allow Sonos traffic. To do this I created two port groups, one for UDP and one for TCP. each of them has a corresponding firewall rule.\nAllow Sonos TCP I created a port group for my TCP traffic. See below.\n1 2 3 SRC SONOS - DST STREAM-DEVICE - TCP TCP-3401 TCP30000-60000 In the rule below you will notice there is a destination group as well in addition to the ports. I have added the IP\u0026rsquo;s of my Sonos speakers to a group so I can only open a couple pinholes for traffic instead of the whole VLAN. See below.\nAllow Sonos UDP I created a port group for my TCP traffic. See below.\n1 2 3 SRC SONOS - DST STREAM-DEVICE - UDP UDP-1901 UDP30000-60000 I am using the same port group for the source as I did above for the IP\u0026rsquo;s of the Sonos speakers.\nOrdering of the rules The ordering of the firewall rules is extremely important. Make sure you have your allow rules before your deny rules. If not things will not work.\nSee below for my final set of rules.\nCredit https://en.community.sonos.com/troubleshooting-228999/multiple-subnets-vlans-and-sonos-workable-clavister-solution-30950\n","date":"2019-02-11T13:24:00-05:00","image":"https://www.jeffsloyer.io/post/sonos-usg-firewall-ports/wall_hu_2062b37a696ef10f.jpg","permalink":"https://www.jeffsloyer.io/post/sonos-usg-firewall-ports/","title":"Firewall Ports for the Unifi USG and Sonos Speakers"},{"content":"Background Ever since I have switched over to Ubiquiti\u0026rsquo;s Unifi setup for my home I have been searching for a way to eliminate AT\u0026amp;T\u0026rsquo;s residential gateway from my setup. I have AT\u0026amp;T Fiber and I detest AT\u0026amp;T\u0026rsquo;s residential gateway. I won\u0026rsquo;t go into the reasons now but just know the list is almost endless. It would be great if AT\u0026amp;T just allowed you not to use that if you have a router of your own. I would love to see AT\u0026amp;T allow residential fiber customers on their PON network to bypass the ONT but that might be too much to ask. I will gladly take a set in the right direction by eliminating the residential gateway in my routing to the Internet.\nI recently stumbled on some amazing instructions when researching why AT\u0026amp;T uses a public IP that isn\u0026rsquo;t assigned to them, 1.1.1.1. If you aren\u0026rsquo;t aware of 1.1.1.1, it\u0026rsquo;s Cloudflare\u0026rsquo;s new DNS servers that promise to be faster than Google\u0026rsquo;s public DNS servers. If you aren\u0026rsquo;t using them I would highly encourage you to do so, check out this for more information. Turns out I found a blog post that documented if you remove the AT\u0026amp;T gateway you can then route to 1.1.1.1 on AT\u0026amp;T\u0026rsquo;s network and not get blocked.\nIf you don\u0026rsquo;t have your own Unifi USG you can order one on Amazon.\nIf you don\u0026rsquo;t have a Unifi Cloud Key you can use the following to get one off of Amazon also.\nJust a note here, I am not taking any credit for any of the instructions, I am just merely adding my custom work I needed to do to get it working. The instructions were great actually, there is just a step at the end that is a little confusing and hard. You have to generate a custom config for your USG and its not straightforward on how to do this so I am posting my experience with it.\nThe original instructions can be found at https://blog.taylorsmith.xyz/att-uverse-modem-bypass-unifi-usg/.\nCustom Config In the instructions you will eventually get to a point where you have to generate a custom config file from your USG, the output will be a file called configdump.txt.\nYou will need to heavily modify that file to remove information that you can configure in the Unifi UI to avoid issues going forward. The author provided a wonderful example of his config file called config.gateway.json, it can be found below.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 { \u0026#34;interfaces\u0026#34;: { \u0026#34;ethernet\u0026#34;: { \u0026#34;eth0\u0026#34;: { \u0026#34;address\u0026#34;: [ \u0026#34;dhcp\u0026#34; ], \u0026#34;description\u0026#34;: \u0026#34;WAN\u0026#34;, \u0026#34;dhcp-options\u0026#34;: { \u0026#34;client-option\u0026#34;: [ \u0026#34;retry 60;\u0026#34; ], \u0026#34;default-route\u0026#34;: \u0026#34;update\u0026#34;, \u0026#34;default-route-distance\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;name-server\u0026#34;: \u0026#34;no-update\u0026#34; }, \u0026#34;duplex\u0026#34;: \u0026#34;auto\u0026#34;, \u0026#34;firewall\u0026#34;: { \u0026#34;in\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_IN\u0026#34; }, \u0026#34;local\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_LOCAL\u0026#34; }, \u0026#34;out\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_OUT\u0026#34; } }, \u0026#34;speed\u0026#34;: \u0026#34;auto\u0026#34;, \u0026#34;vif\u0026#34;: { \u0026#34;0\u0026#34;: { \u0026#34;address\u0026#34;: [ \u0026#34;dhcp\u0026#34; ], \u0026#34;description\u0026#34;: \u0026#34;WAN VLAN 0\u0026#34;, \u0026#34;dhcp-options\u0026#34;: { \u0026#34;default-route\u0026#34;: \u0026#34;update\u0026#34;, \u0026#34;default-route-distance\u0026#34;: \u0026#34;210\u0026#34;, \u0026#34;name-server\u0026#34;: \u0026#34;update\u0026#34; }, \u0026#34;firewall\u0026#34;: { \u0026#34;in\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_IN\u0026#34; }, \u0026#34;local\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_LOCAL\u0026#34; } }, \u0026#34;mac\u0026#34;: \u0026#34;E0:BB:CC:DD:EE:FF\u0026#34; } } }, \u0026#34;eth2\u0026#34;: { \u0026#34;address\u0026#34;: [ \u0026#34;dhcp\u0026#34; ], \u0026#34;description\u0026#34;: \u0026#34;AT\u0026amp;T router\u0026#34;, \u0026#34;dhcp-options\u0026#34;: { \u0026#34;client-option\u0026#34;: [ \u0026#34;retry 60;\u0026#34; ], \u0026#34;default-route\u0026#34;: \u0026#34;update\u0026#34;, \u0026#34;default-route-distance\u0026#34;: \u0026#34;220\u0026#34;, \u0026#34;name-server\u0026#34;: \u0026#34;update\u0026#34; }, \u0026#34;duplex\u0026#34;: \u0026#34;auto\u0026#34;, \u0026#34;firewall\u0026#34;: { \u0026#34;in\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_IN\u0026#34; }, \u0026#34;local\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_LOCAL\u0026#34; }, \u0026#34;out\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_OUT\u0026#34; } }, \u0026#34;speed\u0026#34;: \u0026#34;auto\u0026#34; } } }, \u0026#34;port-forward\u0026#34;: { \u0026#34;wan-interface\u0026#34;: \u0026#34;eth0.0\u0026#34; }, \u0026#34;service\u0026#34;: { \u0026#34;dns\u0026#34;: { \u0026#34;dynamic\u0026#34;: { \u0026#34;interface\u0026#34;: { \u0026#34;eth0.0\u0026#34;: { \u0026#34;service\u0026#34;: { \u0026#34;custom-cloudflare\u0026#34;: { \u0026#34;host-name\u0026#34;: [ \u0026#34;websiteurl\u0026#34; ], \u0026#34;login\u0026#34;: \u0026#34;email\u0026#34;, \u0026#34;options\u0026#34;: [ \u0026#34;zone=websiteurl use=web ssl=yes\u0026#34; ], \u0026#34;password\u0026#34;: \u0026#34;apikey\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;cloudflare\u0026#34;, \u0026#34;server\u0026#34;: \u0026#34;www.cloudflare.com\u0026#34; } } } } } }, \u0026#34;nat\u0026#34;: { \u0026#34;rule\u0026#34;: { \u0026#34;5010\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;masquerade for WAN\u0026#34;, \u0026#34;outbound-interface\u0026#34;: \u0026#34;eth0.0\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;all\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;masquerade\u0026#34; } } }, \u0026#34;upnp2\u0026#34;: { \u0026#34;listen-on\u0026#34;: [ \u0026#34;eth1\u0026#34; ], \u0026#34;nat-pmp\u0026#34;: \u0026#34;enable\u0026#34;, \u0026#34;secure-mode\u0026#34;: \u0026#34;enable\u0026#34;, \u0026#34;wan\u0026#34;: \u0026#34;eth0.0\u0026#34; } } } The only problem with the above file is I had a VPN setup and running and after going through the author\u0026rsquo;s instructions everything worked except the VPN so I had to go through and add in the relative bits related to my VPN setup on my USG.\nBelow is my config file config.gateway.json with some sensitive information nulled out.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 { \u0026#34;interfaces\u0026#34;: { \u0026#34;ethernet\u0026#34;: { \u0026#34;eth0\u0026#34;: { \u0026#34;address\u0026#34;: [ \u0026#34;dhcp\u0026#34; ], \u0026#34;description\u0026#34;: \u0026#34;WAN\u0026#34;, \u0026#34;dhcp-options\u0026#34;: { \u0026#34;client-option\u0026#34;: [ \u0026#34;retry 60;\u0026#34; ], \u0026#34;default-route\u0026#34;: \u0026#34;update\u0026#34;, \u0026#34;default-route-distance\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;name-server\u0026#34;: \u0026#34;no-update\u0026#34; }, \u0026#34;duplex\u0026#34;: \u0026#34;auto\u0026#34;, \u0026#34;firewall\u0026#34;: { \u0026#34;in\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_IN\u0026#34; }, \u0026#34;local\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_LOCAL\u0026#34; }, \u0026#34;out\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_OUT\u0026#34; } }, \u0026#34;speed\u0026#34;: \u0026#34;auto\u0026#34;, \u0026#34;vif\u0026#34;: { \u0026#34;0\u0026#34;: { \u0026#34;address\u0026#34;: [ \u0026#34;dhcp\u0026#34; ], \u0026#34;description\u0026#34;: \u0026#34;WAN VLAN 0\u0026#34;, \u0026#34;dhcp-options\u0026#34;: { \u0026#34;default-route\u0026#34;: \u0026#34;update\u0026#34;, \u0026#34;default-route-distance\u0026#34;: \u0026#34;210\u0026#34;, \u0026#34;name-server\u0026#34;: \u0026#34;update\u0026#34; }, \u0026#34;firewall\u0026#34;: { \u0026#34;in\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_IN\u0026#34; }, \u0026#34;local\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_LOCAL\u0026#34; } }, \u0026#34;mac\u0026#34;: \u0026#34;ab:cd:ef:12:34:56\u0026#34; } } }, \u0026#34;eth2\u0026#34;: { \u0026#34;address\u0026#34;: [ \u0026#34;dhcp\u0026#34; ], \u0026#34;description\u0026#34;: \u0026#34;AT\u0026amp;T router\u0026#34;, \u0026#34;dhcp-options\u0026#34;: { \u0026#34;client-option\u0026#34;: [ \u0026#34;retry 60;\u0026#34; ], \u0026#34;default-route\u0026#34;: \u0026#34;update\u0026#34;, \u0026#34;default-route-distance\u0026#34;: \u0026#34;220\u0026#34;, \u0026#34;name-server\u0026#34;: \u0026#34;update\u0026#34; }, \u0026#34;duplex\u0026#34;: \u0026#34;auto\u0026#34;, \u0026#34;firewall\u0026#34;: { \u0026#34;in\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_IN\u0026#34; }, \u0026#34;local\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_LOCAL\u0026#34; }, \u0026#34;out\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;WAN_OUT\u0026#34; } }, \u0026#34;speed\u0026#34;: \u0026#34;auto\u0026#34; } } }, \u0026#34;port-forward\u0026#34;: { \u0026#34;wan-interface\u0026#34;: \u0026#34;eth0.0\u0026#34; }, \u0026#34;service\u0026#34;: { \u0026#34;dns\u0026#34;: { \u0026#34;dynamic\u0026#34;: { \u0026#34;interface\u0026#34;: { \u0026#34;eth0.0\u0026#34;: { \u0026#34;service\u0026#34;: { \u0026#34;dyndns\u0026#34;: { \u0026#34;host-name\u0026#34;: [ \u0026#34;domain.dyndns.org\u0026#34; ], \u0026#34;login\u0026#34;: \u0026#34;someuser\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxxxxx\u0026#34; } } } } }, \u0026#34;forwarding\u0026#34;: { \u0026#34;except-interface\u0026#34;: [ \u0026#34;eth0.0\u0026#34; ] } }, \u0026#34;nat\u0026#34;: { \u0026#34;rule\u0026#34;: { \u0026#34;5010\u0026#34;: { \u0026#34;description\u0026#34;: \u0026#34;masquerade for WAN\u0026#34;, \u0026#34;outbound-interface\u0026#34;: \u0026#34;eth0.0\u0026#34;, \u0026#34;protocol\u0026#34;: \u0026#34;all\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;masquerade\u0026#34; } } }, \u0026#34;lldp\u0026#34;: { \u0026#34;interface\u0026#34;: { \u0026#34;eth0.0\u0026#34;: { \u0026#34;disable\u0026#34;: \u0026#34;\u0026#39;\u0026#39;\u0026#34; } } } }, \u0026#34;vpn\u0026#34;: { \u0026#34;ipsec\u0026#34;: { \u0026#34;ipsec-interfaces\u0026#34;: { \u0026#34;interface\u0026#34;: [ \u0026#34;eth0.0\u0026#34; ] } }, \u0026#34;l2tp\u0026#34;: { \u0026#34;remote-access\u0026#34;: { \u0026#34;dhcp-interface\u0026#34;: \u0026#34;eth0.0\u0026#34; } } } } The most important thing to note is anywhere you find eth0, you need to replace it with eth0.0. It took some guessing and checking and having to reset my USG a couple times but I eventually got things working.\nMake sure to special attention to the config above. You only need to copy down to an individual key pair in the JSON to get to eth0. However if a key is called eth0 you will need to copy everything below it as its the key for that information. A good example of this can be found in the dns section above.\nI would highly encourage you to use the above file as a starting point and modify it as you see fit if you have any other information referencing eth0.\nSpeed Test Results Below are a couple speed tests I captured after. My speeds roughly stayed the same which is amazing as I have seen some instructions that greatly reduce the speed with a bridge running on the USG. I did notice the ping times went down a couple milliseconds, I will take that any day, things feel a lot more snappier now!!!\nSpeed tests AT\u0026amp;T Celito Fiber Credits Again I don\u0026rsquo;t want to detract from the amazing work that was done at https://blog.taylorsmith.xyz/att-uverse-modem-bypass-unifi-usg/.\nAlso shout out to Jay Soffian for writing the EAP Proxy, checkout the Github project and give it a star for his awesome work!\n","date":"2018-04-04T13:24:00-05:00","image":"https://www.jeffsloyer.io/post/att-uverse-modem-bypass-unifi-usg/secure_hu_a802a666c6795576.jpg","permalink":"https://www.jeffsloyer.io/post/att-uverse-modem-bypass-unifi-usg/","title":"ATT Uverse Modem Bypass - UniFi USG"},{"content":"Most people do not think about backups or want to take the time to set one up or spend the money. Boy is that a mistake\u0026hellip; Most people (myself included) are in that boat and they realize they need to backup their data after its too late and they have lost that precious photo of their baby being born.\nThere are multiple methods for backing up your data, they range from a thumb drive to remote backup. The various mediums range in price from free all the way up to several hundred dollars a year. For me you can\u0026rsquo;t put a price on your precious home videos and photos\u0026hellip; The different backup medium\u0026rsquo;s also range in complexity in terms of ease of use and setup.\nMy backup strategy For about the last year I have been backing up all of my computers to Crashplan. I was in love with how simple it was use and when the day came that I needed to restore something I could go in their application, search for the file, and restore it. I could even restore deleted files that were deleted months ago. About 4 months ago I started backing up my Macbook Pro with Time Machine. Crashplan was too slow with upload speeds so I decided that if I needed something quickly restored I have it locally.\nThis worked out great until I moved recently\u0026hellip; At my old residence I had Time Warner Cable Internet (now Spectrum), my connection speed was 300Mbps down and 20Mbps up. Crashplan was usually close to consuming the full speed of the link with other things sharing my upload speed. However, when I moved to my new residence I got AT\u0026amp;T Fiber which offers a full 1Gbps down and 1Gbps up speed. I have security cameras (nanny cam\u0026rsquo;s) at my place and they record motion to a local Windows server I have. At my old place I was only running 2 cameras so Crashplan was able to keep up. However, at the new place I was running 5 camera\u0026rsquo;s and Crashplan was not able to keep up. The backup time keeps increasing. As of this writing the backup time is now up to 10 days\u0026hellip;\nI contacted Crashplan\u0026rsquo;s support and they responded pretty quick and I was quite impressed initially. They sent me a couple blog links on how to optimize my backups and allow larger files to be uploaded. I am uploading photos averaging around 20MB/piece from my DSLR to 4GB video files that come from the security cameras. Crashplan reccomended that I try to tune the Java JVM and give it more memory to help upload those large files. Initially I thought it worked but it didn\u0026rsquo;t\u0026hellip; I opened another ticket with them and they gave me a couple more blog posts to try. This time they reccomended tuning some of the parameters around how much CPU Crashplan can use. I tried that again I was only getting best case 3.6Mbps upload speed to Crashplan on a 1Gbps link\u0026hellip;\nTo add insult to injury throughout this back and forth with support Crashplan announced they were discontinuing their home backup service and you needed to upgrade to their Pro or Small Business version or move to Carbonite with a discount. I was still somewhat happy with Crashplan and all of my data was backed up there I decided to upgrade to their Small Business plan.\nAt this point I was getting pretty frustrated. I decided to open another ticket with Crashplan and asked again what else to do and I got a less than ideal answer back from them, a snippet is below\u0026hellip;\nHello Jeff,\nThank you for contacting Code42 support!\nCrashPlan normally backs up at a speed of 1-3 mbps or 10-30 GB a day.\nIt\u0026rsquo;s important to remember that like other services that share resources with a pool of users (i.e. cable internet or cellular data), CrashPlan\u0026rsquo;s speed varies depending on the number of simultaneous users and what they are uploading or downloading at the time. Though we do prioritize the downloads from our server, we are still bound by the number of users that are currently uploading or downloading from that server.\nIf you happen to have a very fast internet connection, it is unlikely that backups or restores from CrashPlan Central will be able to match your upload or download limit. This is not a bug - it\u0026rsquo;s the nature of a shared service that is designed to be affordable. We work to ensure that everyone gets sufficient bandwidth for a very reasonable price.\nWe\u0026rsquo;re continually monitoring usage across our data centers and we are strategically adding capacity (servers, storage and bandwidth) to our infrastructure to deliver the best upload speeds we can while preserving our competitive pricing.\nIf you have any further CrashPlan questions or concerns, please do not hesitate to reach out to us\nRegards, Code42\nCrashplan are you serious??? I can only backup at speeds at 1-3Mbps???? This isn\u0026rsquo;t the 1990\u0026rsquo;s and I am not running a DSL line\u0026hellip; One of my security camera\u0026rsquo;s alone can produce over 30GB a day, no wonder why my backup time continued to increase to 10 days\u0026hellip; At this point I had to jump ship\u0026hellip;\nMy new backup strategy Fast forward to my current backup strategy. I couldn\u0026rsquo;t be happier now, I have an old Macmini with an external 4TB drive that I let my Macbook Pro use TimeMachine and backup to. I use the Western Digital 4TB external drive, see below for a link to Amazon.\nThis is nice if I have complete failure of my primary machine. With this I can completely restore my primary machine in about an hour. Additionally this is nice as well as when you get a new Mac to replace your current one you can restore from a TimeMachine backup and having the backup locally you can be up and running on a new Macbook in a couple hours.\nBesides backing up locally I now Backup to Backblaze with all 3 of my machines. My primary machine (Macbook Pro) backs up to my Mac Mini and then Backblaze then backs up the Mac Mini as well. This is quite nice as if I have a drive failure where my Time Machine backup resides I can restore it.\nFor my last machine, my NVR for my security cameras all of the footage backs up to Backblaze now. The speeds are quite amazing, I have seen over 300Mbps upload speed to Backblaze, so much better than the 3.6Mbps to Crashplan!\nTo be fair I did tune it quite a bit, see the screenshot below. I allowed Backblaze to use 20 threads as well as no caps to achieve that speed\u0026hellip;\nConclusion Based on the quite cheap price and speed of Backblaze I have been incredibly happy! I plan on staying with Backblaze for the foreseeable future!\nIf you want to sign up for Backblaze please use the link below!\nSign up for Backblaze\nAdditionally Backblaze published a blog post themselves on switching as well. I would encourage you to give that a read as well.\nPlease follow me on Twitter at @jsloyer and follow me on Youtube!\n","date":"2017-12-06T14:11:14-05:00","image":"https://www.jeffsloyer.io/post/backblaze-vs-crashplan/alpine_hu_29cf33e2424f0b58.jpg","permalink":"https://www.jeffsloyer.io/post/backblaze-vs-crashplan/","title":"Backblaze vs Crashplan"},{"content":"I haven\u0026rsquo;t posted in awhile because I have taken a new role at IBM and helped lead the development of the new IBM Bluemix Container Service that allows you to run managed Kubernetes clusters on IBM.\nFor a little background, IBM has introduced a managed Kubernetes Service, for more information please read the announce post here.\nCabin is a pretty cool mobile app that lets you manage your Kubernetes cluster through your Android or iPhone. Check out the video below on a walkthrough of Cabin.\nCreate your Bluemix account To get started you will first need a Bluemix account, head over to bluemix.net and sign up.\nCLI Setup Once you sign up you will need to download our CLI. Head over to http://clis.ng.bluemix.net to download our installer. Open the installer and go through the prompts to install the CLI.\nOnce you have the CLI you will need to login to the CLI, to do that do the following.\n1 bx login It will ask for your username and password. If you have an account already it might ask you to select an account, org, and space.\nOnce you are logged in you will need to download our plugin to create a Kubernetes cluster. To do that do the following.\n1 bx plugin install container-service -r Bluemix Create your Kubernetes Cluster To create a free Kubernetes cluster run the following, replacing clustername with anything of your choosing:\n1 2 bx cs init bx cs cluster-create --name clustername If you had a paid account you can create a cluster with the following command. It might ask you for VLAN\u0026rsquo;s. If it does you can get your available VLAN\u0026rsquo;s by running bx cs vlans dal10.\n1 2 bx cs init bx cs cluster-create --name clustername --datacenter dal10 --workers 3 --machine-type b1c.4x16 An example of choosing your own VLAN\u0026rsquo;s you will see below. Also, you can customize the machine type by listing all the available machine types, run bx machine-types dal10. Note you will need to enter the VLAN ID.\n1 2 bx cs init bx cs cluster-create --name clustername --datacenter dal10 --public-vlan 12356 --private-vlan 67891 --workers 3 --machine-type u1c.16x64 Setup Cabin The following instructions are quite hacky and we will be rolling out something more permanent and easier in the near future.\nFirst you will need to download the cluster config for your Kubernetes cluster. You will need to wait until the cluster is provisioned. To see if it\u0026rsquo;s been provisioned run bx cs clusters. Under state it should show deployed.\nNext, you will need to download the Kube config, to do that run what is below replacing clustername with the name of your cluster.\n1 bx cs cluster-config clustername It will download a file and print out something like export KUBECONFIG=/Users/jsloyer/.bluemix/plugins/container-service/clusters/jefftest/kube-config-prod-dal10-jefftest.yml. Run the command that it prints out, if you are on Windows it will be slightly different, it will start with set.\nNext, you will need the hostname of your cluster, to get that run the following replacing clustername with the name of your cluster.\n1 bx cs cluster-get clustername You will want to copy the Master URL. I have pasted mine below omitting my port and part of my IP.\n1 2 3 4 5 6 7 8 9 10 11 $ bx cs cluster-get jefftest Retrieving cluster jefftest... OK Name:\tjefftest ID:\txxxxxx Created:\t2017-03-28T22:54:50+0000 State:\tdeployed Master URL:\thttps://169.47.xxx.xxx:xxxx Ingress host:\t- Ingress secret:\t- Workers:\t1 Lastly, you will need to get the token for your Kube cluster. To do that run the following.\n1 kubectl get secrets | grep default-token It will output something like the following:\n1 2 $ kubectl get secrets | grep default-token default-token-gjswg kubernetes.io/service-account-token 3 21h In the following command replace xxxx with the couple of random characters from the command above.\n1 kubectl get secret default-token-xxxx -o yaml | grep token It is going to output a bunch of stuff, you are going to want to copy the value for token for the next step.\nWith the copied value for token run the following, note the following will only work on Mac or Linux\u0026hellip; You will want to replace token with the really long value you copied.\n1 echo token | base64 --decode If everything worked you have something outputted that starts with ey. It if outputs some garbled text you probably copied it wrong, in writing this I missed a letter on the beginning of mine so be careful.\nyou can then use that in app for your token\nOpen up the Cabin app on your phone, if you haven\u0026rsquo;t downloaded it you can download it from Google Play or the App Store by searching for cabin kubernetes.\nOpen the app enter the Master URL from a couple steps above in the URL field, make sure you have https:// and the port after the IP address.\nUnder authentication tap Token, paste in the value for the token from the previous step, remember it starts with ey, for a configured cluster, see the screenshot below.\nCabin is pretty cool, you can exec into containers and view logs and almost do anything with your Kube Cluster. I would love to see the SkipppBox guys open source this\u0026hellip;\nThats it, you are configured to connect to your Kubernetes cluster on the IBM Bluemix Containers Service. Please leave any comments or feedback below. If you are a Windows user I would love some comments on the steps to get this working :).\nKnown Issues Tiller seems busted which deploys apps into the cluster. For more info check out this GitHub issue. Feedback Please reach out to us on Slack at https://ibm-container-service.slack.com.\n","date":"2017-03-29T09:45:24-05:00","image":"https://www.jeffsloyer.io/post/ibm-container-service-cabin/cabin_hu_599b2ddd537447ec.jpg","permalink":"https://www.jeffsloyer.io/post/ibm-container-service-cabin/","title":"Using Cabin with the IBM Bluemix Container Service"},{"content":"Recently at work I have been struggling with building a small/minimized Docker container of a Go app I have been working on. I started with busybox but it has a major short coming\u0026hellip; CA certificates. It isn\u0026rsquo;t trivial to get CA Certs on a busybox container. This problem effectively prevents you from using SSL or TLS with your app\u0026hellip; This is a non-starter\u0026hellip;\nEnter Alpine I was doing some reading and I have seen a couple articles mention Alpine, its effectively a slimmed down version of busybox but it makes it trivially easy to install packages, in my case CA Certificates! At this point I was really excited but I ran into some issues trying to compile the binary.\nSolution The solution is actually pretty simple, you need to build your Go app inside of a container and then copy the built container to your \u0026ldquo;production\u0026rdquo; Alpine image.\nMy solution uses the Makefile, there is different ways of doing this but this is the simplest.\nThe first addition to the Makefile is the following.\n1 2 3 .PHONY: buildgo buildgo: CGO_ENABLED=0 GOOS=linux go build -ldflags \u0026#34;-s\u0026#34; -a -installsuffix cgo . The above is intended to be run inside of a container but you can run it anywhere. What it does is builds a binary that is statically linked with CGO disabled so it uses the statically linked cgo binary on in the container. This is important as Alpine uses a custom lightweight subset of glibc called libc.\nThe next stanza you need for your Makefile actually builds two containers. One is your build container based on the golang image and then copies the binary to your Alpine container.\n1 2 3 4 5 6 7 .PHONY: builddocker builddocker: docker build -t yourorg/yourproject-build -f ./Dockerfile.build . docker run -t yourorg/yourproject-build /bin/true docker cp `docker ps -q -n=1`:/go/src/github.com/yourorg/yourproject/yourproject . chmod 755 ./yourproject docker build -t yourorg/yourproject . To make the above work you need two Docker files. They are below\u0026hellip;\nNote the following is assuming your depencies are already downloaded, I do this with a make task, make deps.\n1 2 3 .PHONY: deps deps: glide install This is nice/elegant as you don\u0026rsquo;t have to run this in the container so if you have private repo\u0026rsquo;s you don\u0026rsquo;t need to copy in ssh keys or GitHub tokens to download source code. Just make sure your don\u0026rsquo;t have a .dockerignore file as things in that file won\u0026rsquo;t be copied over\u0026hellip;\nDockerfile.build\n1 2 3 4 5 6 7 FROM golang:1.7.1 WORKDIR /go/src/github.com/yourorg/yourproject/ ADD . /go/src/github.com/yourorg/yourproject/ RUN make buildgo CMD [\u0026#34;/bin/bash\u0026#34;] Dockerfile\n1 2 3 4 5 6 7 8 9 10 11 12 FROM alpine COPY yourproject /go/bin/ RUN apk add --update --no-cache ca-certificates ENV GOPATH /go ENTRYPOINT [\u0026#34;/go/bin/yourproject\u0026#34;] # Service listens on port 6969. EXPOSE 6969 The above assumes your binary is named the same as your project name.\nThe magic in Dockerfile is the ability to install the CA certs with a single command.\nGotchas The only issue with disabling CGO is that some functionality in go requires it, most notably is from the os/user package, the function user.Current() makes use of it to determine a user\u0026rsquo;s home directory. You might get an error like the following\u0026hellip;\n1 user: Current not implemented on linux/amd64 The Apache Mesos project ran into this, you can see their solution. Their solution does a shortcoming though with their looping\u0026hellip; Check out my change in the Go library for IBM Softlayer. The pull PR is available here.\nPlease follow me on Twitter at @jsloyer and follow me on Youtube!\n","date":"2016-12-19T14:11:14-05:00","image":"https://www.jeffsloyer.io/post/cross-compiling-docker-alpine-golang/alpine_hu_29cf33e2424f0b58.jpg","permalink":"https://www.jeffsloyer.io/post/cross-compiling-docker-alpine-golang/","title":"Cross Compiling Golang with a Docker Alpine Container"},{"content":"This post has been a long time going and much overdue, it has almost been 12 months since publishing the follow up to my previous post Why I Chose Hugo Over Wordpress. But I am finally going to take the time and explain all the technical parts about how I made this blog work with Hugo.\nSetting up the site First to get started you need to install Hugo.\n1 brew update \u0026amp;\u0026amp; brew install hugo Next you need to create a basic Hugo site.\n1 hugo new site jsloyer With Hugo you you can use themes, I am using a modified version of StartBootstrap Clean Blog.\nI embedded the theme into my GitHub project.\nOnce you embed the theme you need to tell Hugo to use the theme.\nYou do this in config.toml.\n1 theme = \u0026#34;startbootstrap-clean-blog\u0026#34; Speaking of git you need to setup a GitHub project, the name is really important\u0026hellip; If you are publishing the Hugo site under your own GitHub org, ie your username, the git project needs to match that. For me my GitHub username is jsloyer so my git project name is jsloyer as well. The reason for this is how GitHub pages works in picking up the build and publishing for a GitHub pages site.\nYou will be doing all of your work on the master branch. Think of the master branch as you would with any of piece of software, the master branch is the raw code, in this case just markdown. There is another special magic branch called gh-pages that we will go through later that makes your repo into a GitHub pages site.\nCreating a post So next we need to create our first post! To do this its pretty simple\u0026hellip;\n1 hugo new post/good-to-great.md Next I start up Hugo to see how the site will look.\n1 hugo server --buildDrafts This starts Hugo in dev mode where you can see a post while you are working on it. The beauty is you can even check the unfinished post into git but until you flip the magic draft setting on a post it won\u0026rsquo;t be live on the Internet.\nAs you make changes to your post and save it Hugo will automatically reload in the browser what the post will look like.\nBefore we jump into how to take a post live lets look at some of the metadata in the post\u0026hellip; Here is some metadata for a previous post of mine.\n1 2 3 4 5 6 7 8 9 10 +++ categories = [\u0026#34;Other\u0026#34;] date = \u0026#34;2016-01-08T14:11:14-05:00\u0026#34; description = \u0026#34;\u0026#34; draft = false image = \u0026#34;/original-images/migrate.jpg\u0026#34; tags = [\u0026#34;wordpress\u0026#34;, \u0026#34;migrate\u0026#34;] title = \u0026#34;Why I Chose Hugo over Wordpress\u0026#34; +++ You can set some various pieces of information for a post. For my particular theme each post has a Jumbotron image, that is set via the image attribute. More on images later\u0026hellip; You can also set tags as well as the title of the post. The most interesting bit here is the draft = false line. This is what I was referring to above in controlling when a post gets published. Once you feel like your post is ready just change it to draft = true.\nPublishing The next step is publishing your post, once you set the draft = true for a post you need to check this file into Git.\n1 2 3 git add . git commit -m \u0026#34;my awesome post\u0026#34; git push origin master At this point you think you might be done but you aren\u0026rsquo;t you need to setup GitHub Pages and a pipeline\u0026hellip;\nI chose Wercker as my continuous delivery (CD) engine for this. It was incredibly easy to setup a pipeline to build the site as well as deploy the site back to GitHub.\nBefore we get into the pipeline we need to setup the git project as a GitHub pages site.\nGoto the settings page for your project, for me its https://github.com/jsloyer/jsloyer/settings.\nScroll down to the bottom\u0026hellip;\nClick \u0026ldquo;Launch automatic page generator\u0026rdquo;, see below. Go through the wizard, it really doesn\u0026rsquo;t matter what you choose here, you are going to replace the content anyways\u0026hellip;\nOnce you have this setup it might take a little bit but your site will be available. For example my site without the custom domain name is http://jsloyer.github.io/jsloyer. Replace your GitHub username with mine and you will be able to access the default site.\nNote: If you want to use a custom domain name I\u0026rsquo;ll include the instructions below, for example my site is hosted on www.jeffsloyer.io.\nAutomatic Pipeline/Publishing The next step is to to get automatic publishing setup. So what happens for me is when I check in a new commit to the master branch, Wercker builds my images and builds the site and publishes it back to the gh-pages branch automatically.\nTo do this you need a file called werkcer.yml in your project. Below is a copy of mine.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 box: nodesource/node build: steps: - install-packages: packages: graphicsmagick - npm-install - grunt: tasks: processimages - arjen/hugo-build: version: \u0026#34;0.14\u0026#34; theme: startbootstrap-clean-blog deploy: steps: - install-packages: packages: git ssh-client - lukevivier/gh-pages@0.2.1: token: $GIT_TOKEN domain: www.jeffsloyer.io basedir: public The above yaml file will build my Hugo site for me as well as build my images in an optimized format as well. The only bit you need to change is if you want to use a specific theme, if you don\u0026rsquo;t want to use the one that I am using change the following to the values you need.\n1 theme: startbootstrap-clean-blog Let\u0026rsquo;s take a bit and talk through my automatic image minimization and rendering. During build time my images are compressed and minimized to different sizes. I only check in high quality original images and the build process optimizes them for me. To do that you need two files. They are below. I am not going to go through how it works but basically all you have to do is run grunt processimages and the tasks will optimize your images\u0026hellip;\npackage.json\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \u0026#34;name\u0026#34;: \u0026#34;blog\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.0.1\u0026#34;, \u0026#34;repository\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;git\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://github.com/jsloyer/jsloyer.git\u0026#34; }, \u0026#34;author\u0026#34;: \u0026#34;Jeff Sloyer\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;glob\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;grunt\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;grunt-cli\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;grunt-contrib-concat\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;grunt-contrib-connect\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;grunt-contrib-copy\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;grunt-contrib-jshint\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;grunt-contrib-sass\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;grunt-contrib-uglify\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;grunt-contrib-watch\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;grunt-jekyll\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;grunt-responsive-images\u0026#34;: \u0026#34;^0.1.7\u0026#34;, \u0026#34;grunt-shell\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;image-size\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;yamljs\u0026#34;: \u0026#34;*\u0026#34; } } Gruntfile.js\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 var grunt = require(\u0026#39;grunt\u0026#39;), fs = require(\u0026#39;fs\u0026#39;), glob = require(\u0026#39;glob\u0026#39;), sizeOf = require(\u0026#39;image-size\u0026#39;), YAML = require(\u0026#39;yamljs\u0026#39;); grunt.loadNpmTasks(\u0026#39;grunt-contrib-concat\u0026#39;); grunt.loadNpmTasks(\u0026#39;grunt-contrib-connect\u0026#39;); grunt.loadNpmTasks(\u0026#39;grunt-contrib-copy\u0026#39;); grunt.loadNpmTasks(\u0026#39;grunt-contrib-jshint\u0026#39;); grunt.loadNpmTasks(\u0026#39;grunt-contrib-sass\u0026#39;); grunt.loadNpmTasks(\u0026#39;grunt-contrib-uglify\u0026#39;); grunt.loadNpmTasks(\u0026#39;grunt-contrib-watch\u0026#39;); grunt.loadNpmTasks(\u0026#39;grunt-responsive-images\u0026#39;); grunt.loadNpmTasks(\u0026#39;grunt-jekyll\u0026#39;); grunt.loadNpmTasks(\u0026#39;grunt-shell\u0026#39;); grunt.initConfig({ responsive_images: { myTask: { options: { sizes: [{ name: \u0026#39;thumb\u0026#39;, width: 400 },{ name: \u0026#39;medium\u0026#39;, width: 800 },{ name: \u0026#34;large\u0026#34;, width: 1200 }] }, files: [{ expand: true, src: [\u0026#39;**/*.{jpg,gif,png,jpeg}\u0026#39;], cwd: \u0026#39;static/original-images\u0026#39;, dest: \u0026#39;static/images\u0026#39; }] } } }); grunt.registerTask(\u0026#39;resize\u0026#39;, [\u0026#34;responsive_images\u0026#34;]); grunt.registerTask(\u0026#39;imageinfo\u0026#39;, function(){ var done = this.async(); glob(\u0026#39;static/images/**/*.{jpg,gif,png}\u0026#39;, {}, function(err, files){ var existingYml = fs.readFileSync(\u0026#34;static/images.yml\u0026#34;).toString(); var a = existingYml.split(\u0026#34;#!#!#!#!#\u0026#34;); existingYml = a[0].trim(); var data = {}; files.forEach(function(file){ var dimensions = sizeOf(file); var image = { width: dimensions.width, height: dimensions.height, aspect: dimensions.width / dimensions.height } data[file] = image; }) var yamlString = YAML.stringify(data); var yamlHeading = \u0026#34;\\n\\n\\n#!#!#!#!# Do not edit below this line.\\n\u0026#34;; yamlHeading += \u0026#34;# Generated automatically using `grunt imageinfo`\\n\\n\u0026#34;; fs.writeFileSync(\u0026#34;static/images.yml\u0026#34;, existingYml + yamlHeading + yamlString); console.log(\u0026#39;done\u0026#39;); done(); }); }); grunt.registerTask(\u0026#39;processimages\u0026#39;, [\u0026#39;resize\u0026#39;, \u0026#39;imageinfo\u0026#39;]); grunt.registerTask(\u0026#39;default\u0026#39;, [\u0026#39;processimages\u0026#39;]); Check in the above files to GitHub, the files are the following.\nwercker.yml Gruntfile.js package.json The next step is getting a token from GitHub. To generate a token goto https://github.com/settings/tokens.\nYou will want a token with the following permissions. Note once you generate the token copy it because GitHub won\u0026rsquo;t display it to you again\u0026hellip;\nNext we need to goto Wercker and login with our GitHub credentials. Once you have logged in click \u0026ldquo;Create\u0026rdquo; at the top and choose application or just click here. You will need to choose your your repo and I chose to make my pipeline private, it is up to you. Once you have finished that you need enter in yout Gitub token so Wercker and deploy your built Hugo site back to GitHub.\nNext we need to edit the pipeline to deploy to GitHub. To do this click on the workflows tab. For example my link is https://app.wercker.com/jsloyer/jsloyer/workflows.\nUnder pipeline there should already be one called build. Click on build. Scroll down to \u0026ldquo;Ignore Branches\u0026rdquo;, type in gh-pages. We are ignoring the gh-pages branch as we don\u0026rsquo;t ever want to build that, we just build master. Click \u0026ldquo;Update\u0026rdquo;. Go back in your browser. We need to add another pipeline called GitHubPages. We need to set an environment variable called GIT_TOKEN, paste in your GitHub token from earlier, click \u0026ldquo;Protected\u0026rdquo;. Don\u0026rsquo;t worry Wercker won\u0026rsquo;t expose this to the public. For the name enter in GitHubPages. For \u0026ldquo;YML Pipeline name\u0026rdquo; enter in deploy. Save this and you are now finished.\nTo trigger a build check in a file into the master branch, the pipeline should execute and deploy your site back to GitHub Pages. If it doesn\u0026rsquo;t post a comment below and I will help you through it.\nAdvanced Stuff Below I am going to go through some advanced stuff that you probably want\u0026hellip;\nCustom Domain Name For my site my site is available at www.jeffsloyer.io. To do this you need to have the domain name in your config.toml, mine is available here. Additionally you need your domain name in your wercker.yml as well, mine is posted above.\nLastly you need a CNAME entry with your registrar to point to GitHub. For more information go here. The CNAME record should point to your-username.GitHub.io. For example my site www.jeffsloyer.io has a CNAME record that points to jsloyer.GitHub.io. It migh take a bit for DNS to update, depends on how long of a TTL you have\u0026hellip;\nFollow the instructions here to add the domain name to the GitHub project as well.\nAdd-ons Hugo has a lot of addons, some are even built right in. For example Google Analytics and Disqus.\nTo Google Analytics I just had to add one line to config.toml.\n1 Ganalytics = \u0026#34;UA-xxxx-xxx\u0026#34; To add Disqus integration I just had to also add one line to config.toml.\n1 disqusShortname = \u0026#34;xxxx\u0026#34; Pretty simple\u0026hellip; For a full list of add-ons goto https://gohugo.io/extras.\nAlso please follow me on Twitter at @jsloyer and follow me on Youtube!\n","date":"2016-12-18T14:11:14-05:00","image":"https://www.jeffsloyer.io/post/why-i-chose-hugo-over-wordpress-part2/migrate_hu_b6775d9350c61c0d.jpg","permalink":"https://www.jeffsloyer.io/post/why-i-chose-hugo-over-wordpress-part2/","title":"Why I Chose Hugo over Wordpress - Part 2"},{"content":"I am finally back with my blog, sorry it has been quite awhile. I just recently finished a migration of my blog my running on Wordpress, which was hosted on WPEngine and is a really awesome service, to Github pages. I got tired of using Wordpress and WPEngine cost me about $30/month\u0026hellip; So I decided to migrate the site to Github pages where I can run the site for free.\nWordpress vs. Jekyll So let\u0026rsquo;s back up a bit and talk about why I first went with Wordpress. It mostly came down to speed of getting my site up. I took the easy way out, I didn\u0026rsquo;t want have to deal with managing a VM and maintaing Wordpress so spent a decent amount of time reading about different hosting providers for Wordpress. WPEngine consistently rose to the top mainly for its use of use and speed. At this point I was also dabbling with Github pages but was using Jekyll and didn\u0026rsquo;t have much luck with it. When I was looking at using Jekyll it was being re-written, there was a version with a bunch of Ruby Gems and then a new version. The Ruby Gems version had way more plugins and flexibility but the new version was much simplier to get up and running. I honestly gave it a good try, I spent a couple hours trying to get things working and I couldn\u0026rsquo;t. I am someone who usually never gives up on something, by gosh I\u0026rsquo;ll get that squre to fit into a circle\u0026hellip;\nBut this time, I had to throw up the white flag\u0026hellip; I just couldn\u0026rsquo;t deal with Jekyll anymore, this is when I decided to jump in feet first with WPEngine.\nLife with WPEngine Life was good with WPEngine. It was really easy to crank out a bunch of blog posts, I mean Wordpress has a great WYSIWYG editor. I eventually got my site up and running an launched the site!\nI then realized I needed to optimize the site for speed and SEO. My first task was enabling SSL. This was incredibly easy with WPEngine, just pay them $53 bucks for a year and you get an SSL cert, that was easy\u0026hellip;\nMy next order of business was increasing the speed of Wordpress, WPEngine already does a lot and their infrastructure is top notch but Wordpress needs some help to speed itself up. I followed some stepson speeding up Wordpress, most of it involved caching, minifying, and uglfying assets.\nLife was pretty good at this point but as the site continued to grow it became slower and slower\u0026hellip;\nTime for a change I was talking to a colleague from work, Raymond Camden about our blogs and he mentioned I should check out Hugo. Basically I kind of stopped blogging because WPEngine was too easy, plus I needed a Holiday project as well over Christmas. I started looking into Hugo and could of not been more happy!!!\nBasically Hugo is a static site generator liked Jekyll but way more simplier. Plus Hugo is written in Go and I have been recently learning Go so I was sold!\nHugo vs. Wordpress So honestly you really can not beat the speed of a static site. Wordpress no matter what has to query a database for every request and that adds up. I decided to run my Hugo generated blog on Github Pages for even more speed. Github fronts themselves with Fastly, which is probably the coolest and most pimp CDN out there. Its super fast, like no one can beat them on time to first byte. Fastly uses SSD\u0026rsquo;s in the cache machines so delivering content is blazing fast. Additionally Fastly has an API to configure your site and basically allows you to do everything programatically, plus they have self on-boarding, a big plus that you don\u0026rsquo;t have to call some sales person\u0026hellip;\nI have been using markdown a bit more recently and I felt like this time I was more prepared to jump into markdown. My Hugo site uses marketdown for the content files then HTML for the theme. Its really nice that you can keep your content stored in markdown and its agnostic of the presentation layer (the theme). If you don\u0026rsquo;t want to use markdown thats ok, you can create your content in HTML as well.\nAdditionally, with Hugo I am storing my site on Github and I check in source content and source files such as images. My build process uses Wercker to build my static site and to generate the correctly sized images for my blog as well. Plus Wercker auto-deploys my site to Github Pages whenever there is a checkin!\nMigrating the site In my next post I will go through how I migrated my site from Wordpress to Hugo. Hope this has been informative and hopefully interesting. Please leave some comments below!\nAlso please follow me on Twitter at @jsloyer and follow me on Youtube!\n","date":"2016-01-08T14:11:14-05:00","image":"https://www.jeffsloyer.io/post/why-i-chose-hugo-over-wordpress/migrate_hu_b6775d9350c61c0d.jpg","permalink":"https://www.jeffsloyer.io/post/why-i-chose-hugo-over-wordpress/","title":"Why I Chose Hugo over Wordpress"},{"content":"Following up from my previous post, Canonical recently dropped support for lucid64 which is Ubuntu 10.04 LTS. This affects Cloud Foundry as lucid64 is the basis for most buildpacks. In Cloud Foundry lucid64 is being phased out for Ubuntu 14.04 LTS which is known as cflinuxfs2 in Cloud Foundry.\n1 2 3 4 5 6 Getting stacks in org jbsloyer@us.ibm.com / space dev as jbsloyer@us.ibm.com... OK name description lucid64 Ubuntu 10.04 cflinuxfs2 Ubuntu 14.04.2 trusty The PHP buildpack will take the default system buildpack and right now in Bluemix it is lucid64. This will throw some errors when you try to push your PHP app, for example something like below.\n1 2 3 4 5 6 7 8 It looks like you\u0026#39;re deploying on a stack (currently set to *lucid64*) that\u0026#39;s not supported by this buildpack. That could be because you\u0026#39;re using a recent buildpack release on a deprecated stack. If you\u0026#39;re using the buildpack installed by your CF admin, please let your admin know you saw this error message. If you at one point specified a buildpack that\u0026#39;s at git URL, please make sure you\u0026#39;re pointed at a version that supports this stack. Staging failed: Buildpack compilation step failed FAILED BuildpackCompileFailed To fix it you just need to use the -s cflinuxfs2 argument for the cf push command. Ex.\n1 cf push myapp -b https://github.com/cloudfoundry/php-buildpack.git -s cflinuxfs2 Check out this video for a walk through on how to fix the issue and an explanation of it.\nI would love to hear your feedback and any suggestions you have, please reach out to me on Twitter [@jsloyer](https://twitter.com/jsloyer target=)\n","date":"2015-08-26T11:17:31-05:00","image":"https://www.jeffsloyer.io/post/fixing-common-errors-with-the-php-buildpack-in-bluemix/fedup_hu_c21e522d75dc93cd.jpg","permalink":"https://www.jeffsloyer.io/post/fixing-common-errors-with-the-php-buildpack-in-bluemix/","title":"Fixing common errors with the PHP Buildpack in Bluemix"},{"content":"With the recent shooting in South Carolina in reminds us that criminal\u0026rsquo;s can and will continue to harm people. They seem like random acts to most of us but to a criminal the acts make sense to them? No one can answer this question except the criminal. To peer inside a criminal\u0026rsquo;s would be next to impossible but what if there existed another way to peer inside their mind\u0026rsquo;s? This could be used to try to identify patterns or personality traits that exist. This information could be used to prevent these horrible acts and better humanity.\nSo how would we do this? I work at IBM so the answer is obviously IBM Watson. We all have heard of Watson, IBM Watson beat Ken Jennings on Jeopardy. However there is so much more that Watson can do, check this out for all the cool things Watson can do. One of the really cool services that Watson now provides is something called Personality Insights. This service can analyze the personality of text in meer seconds via a REST API. One of the things IBM is trying to do now is make all these really cool technologies available to everyone and anyone. They are doing it through something called IBM Bluemix. Bluemix is IBM\u0026rsquo;s platform as a service (PaaS), and it has a whole giant catalog of really cool technologies from IBM as well as lots of other third parties. You can sign up for a free 30 day account by going here.\nSo how does this fit back with peering inside of a criminal. Well I hope you guessed the answer, we are going to use Personality Insights to analyze the personality of a couple criminal\u0026rsquo;s and look for some common traits.\nLet\u0026rsquo;s take the most recent horrible attack, the South Carolina church shooting. Dylann Roof posted a manifesto online and we are going to use that as the basis to peer into his mind.\nThere are two ways to try this out for yourself. Let\u0026rsquo;s go through both of them.\nSign up a Bluemix account\nClick the button deploy. The button will automagically deploy the Personality Insights starter app that we are going to use. If you are interested in the code head over to Github.\n[![Deploy to Bluemix](button.png)](https://bluemix.net/deploy?repository=https://github.com/IBM-Bluemix/personality-insights-nodejs.git\u0026amp;cm_mmc=Display-JeffSloyer.io-_-BluemixSampleApp-WatsonCriminalAnalysis-_-Node-WatsonPersonalityInsights-_-BM-DevAd) Once you app is finished deploying click \u0026ldquo;View your app\u0026rdquo;. You will be taken to your app.\nHint, if you are lazy and don\u0026rsquo;t want to do the above steps go here.\nNext we need to get the text from Dylann Roof that we want to analyze. It can be found here. Open the link and copy all the text.\nClick on \u0026ldquo;Clear\u0026rdquo;\n[![clear](clear.jpg)](clear.jpg) Paste the text into the text box [![enter-text](enter-text.jpg)](enter-text.jpg) Click \u0026ldquo;Analyze\u0026rdquo; [![analyze](analyze.jpg)](analyze.jpg) Watson will return us Dylann Roof\u0026rsquo;s personality based on the manifesto in just a matter of seconds.\nYou are unconventional, shrewd and can be perceived as critical. You are unconcerned with art: you are less concerned with artistic or creative activities than most people who participated in our surveys. You are laid-back: you appreciate a relaxed pace in life. And you are intermittent: you have a hard time sticking with difficult tasks for a long period of time.\nMore than most people, your choices are driven by a desire for well-being.\nYou consider helping others to guide a large part of what you do: you think it is important to take care of the people around you. You are relatively unconcerned with tradition: you care more about making your own path than following what others have done. \u0026ndash; IBM Watson Analysis of Dylann Roof\u0026rsquo;s manifesto\nAdditionally Watson provides us a visualization as well.\nLet\u0026rsquo;s next take a look at Anders Behring Breivik, who was responsible for the 2011 attacks in Norway. His manifesto is available here. You will need to convert it to a .txt file. You can do this here. It will email you a copy of the manifesto in a .txt file.\nSo let\u0026rsquo;s repeat the same steps as above.\nClear the text area Paste the text Click Analyze NOTE: You will need to make sure you have deployed the Bluemix app yourself for this one, the text file is really big and the default app does not support really large files.\nYou are shrewd, skeptical and tranquil. You are philosophical: you are open to and intrigued by new ideas and love to explore them. You are imaginative: you have a wild imagination. And you are independent: you have a strong desire to have time to yourself.\nYou are motivated to seek out experiences that provide a strong feeling of prestige.\nYou are relatively unconcerned with both taking pleasure in life and tradition. You prefer activities with a purpose greater than just personal enjoyment. And you care more about making your own path than following what others have done. \u0026ndash; IBM Watson Analysis of Anders Behring Breivik\u0026rsquo;s manifesto\nOne last example. I went to Virginia Tech and I was at the school when the massacre happened there. This one hits quite close to home to me. I was supposed to be in a classroom that fellow students were massacred but I overslept. Let\u0026rsquo;s take a look at Seung Hui Cho’s \u0026ldquo;Manifesto\u0026rdquo;. His manifesto is available here. You will need to convert it to a .txt file. You can do this here. It will email you a copy of the manifesto in a .txt file.\nSo let\u0026rsquo;s repeat the same steps as above.\nClear the text area Paste the text Click Analyze You are boisterous and somewhat shortsighted. You are content: you are content with your level of accomplishment and do not feel the need to set ambitious goals. You are confident: you are hard to embarrass and are self-confident most of the time. And you are carefree: you do what you want, disregarding rules and obligations.\nMore than most people, your choices are driven by a desire for modernity.\nYou consider independence to guide a large part of what you do: you like to set your own goals to decide how to best achieve them. You are relatively unconcerned with tradition: you care more about making your own path than following what others have done. \u0026ndash; IBM Watson Analysis of Seung Hui Cho\u0026rsquo;s manifesto\nLet\u0026rsquo;s do some analysis on all this data now. It looks like all the shooter\u0026rsquo;s from these massacres have the following in common.\nIt looks like from the Charleston and Norway events both share the following traits and a high percentage of both of them.\nAuthority-challenging Self-transcendence Openness to change Also on the flip side they both share the following traits with low percentages, which if you think about it means probably huge red flags.\nConversation (Charleston was 3%, Norway was 11%) Cheerfulness (Charleston 12%, Norway 2%) Trust (Charleston 11%, Norway 8%) Uncompromising (Charleston 9%, 3%) So digging into it a little more by no means am I a psychologist but it seems to me that a person that has low values in conversation, cheerfulness, trust, and uncompromising could definitely be red flags. Additionally, high values in authority-challenging, self-transcendence, openness to change paired with the above low characteristics could be a model to try to detect some of these behaviors and thoughts earlier on.\nGoing forward if police or schools could analyze the text of suspected criminal\u0026rsquo;s before hand maybe these horrible massacre\u0026rsquo;s could of been prevented. Maybe for the Dylann Roof case if the FBI examiner that reviewed Dylann Roof\u0026rsquo;s gun permit had access to a tool like this it could of prevented the whole situation. I know that is kinda big brother but I really believe in a somewhat of an invasion of privacy for the overall good of humanity.\nThis demo could easily be extended to use more automated methods as well. Think of companies like Dropbox analyzing files or your ISP analyzing files. I know this would be quite creepy but it could honestly possibly save lives and prevent these horrible massacres.\nI know this post is kind of controversial but it is good to be talking about this and hopefully some good will come from this. Please leave me feedback below or tweet me @jsloyer.\n","date":"2015-08-24T11:21:03-05:00","image":"https://www.jeffsloyer.io/post/peering-inside-a-criminals-mind-using-ibm-watson/glasses_hu_6ea18c5fad669736.jpg","permalink":"https://www.jeffsloyer.io/post/peering-inside-a-criminals-mind-using-ibm-watson/","title":"Peering Inside a Criminal’s Mind using IBM Watson"},{"content":"This is a follow up post to a previous post on Deploying your Meteor app to Cloud Foundry and Bluemix. In this post we went through how to deploy a Meteor app to Cloud Foundry and Bluemix. In this post we will be going through the same thing except in a video format. Check out the video below.\nI would love to hear your feedback and any suggestions you have, please reach out to me on Twitter [@jsloyer](https://twitter.com/jsloyer target=).\n","date":"2015-08-24T11:03:35-05:00","image":"https://www.jeffsloyer.io/post/video-deploying-your-meteor-app-to-cloud-foundry-and-bluemix/meteor_hu_29b08e086396b49b.jpg","permalink":"https://www.jeffsloyer.io/post/video-deploying-your-meteor-app-to-cloud-foundry-and-bluemix/","title":"(Video) - Deploying your Meteor app to Cloud Foundry and Bluemix"},{"content":"Meteor is a pretty powerful and cool framework for developing modern webapps all in Javascript. It provides some really cool things as a modern UI, responsive code that works on a desktop and a mobile device, and some really slick features with websockets with client and server side rendering.\nI heard about Meteor mid-2014 but it peaked my interest last week when I was at a customer and a developer at the customer was building a Meteor app and they were asking how to run it on Bluemix. Of course doing my job I helped the developer get the app running but it took a couple tweaks to the Cloud Foundry buildpack for Meteor.\nYou might be asking what a buildpack is, that\u0026rsquo;s totally fine. In Cloud Foundry you can use basically any language you want for your app, all you need is some code to laydown the app server or middleware and compile your code together and install dependencies. For Meteor there is a buildpack available but it was slighly out of date.\nLast week and this week I committed some changes to the buildpack to make it more robust and compatible for newer Meteor apps.\nThe buildpack now will allow you to use your existing Meteor app and push it to Cloud Foundry and Bluemix.\nFor the rest of this blog post I am going to walk through on how to build an example Meteor app and push it to Bluemix.\nPre-req\u0026rsquo;s Sign up for a Bluemix account. Go Bluemix and click on Sign-up in the top right hand corner. Meteor installed locally, go Meteor install to install Meteor Cloud Foundry Command Line (CLI) installed, go install CLI for instructions Steps Create a sample Meteor app, we are going to use the leaderboard example\nmeteor create --example leaderboard Push the sample app to Bluemix. Note, this command will not start the app, we will need to choose our database next. Also replace leaderboard with a unique name for your app, for example leaderboard-jbs (my intials).\ncf push leaderboard -b https://github.com/cloudfoundry-community/cf-meteor-buildpack.git --no-start Next we need to choose if we want to use the built on Mongo DB with Cloud Foundry or an external third party MongoLab. It honestly doesn\u0026rsquo;t matter too much but MongoLab is built for scale is more reliable, I would choose MongoLab myself.\nBuilt in MongoDB:\nCreate the database. cf create-service mongodb 100 leaderboard-mongodb\nConnect the database to our app. Replace leaderboard with the name of your app (ex. leaderboard-jbs).\ncf bind-service leaderboard leaderboard-mongodb would then become\ncf bind-service leaderboard-jbs leaderboard-mongodb MongoLab:\nCreate the database. cf create-service mongolab sandbox leaderboard-mongolab\nConnect the database to our app. Replace leaderboard with the name of your app (ex. leaderboard-jbs).\ncf bind-service leaderboard leaderboard-mongolab would then become\ncf bind-service leaderboard-jbs leaderboard-mongolab Start the application. Replace leaderboard with the name of your app\ncf start leaderboard Open up two web browsers and goto the same url, for me my URL would be http://leaderboard-jbs.mybluemix.net. I got this url by putting the name of my app in front of mybluemix.net.\nIn the video below you can see when you choose a player and then click add 5 points the other browser is updated instantly. The example app is saving this information in the Mongo database then using websockets to notify all the connected clients of the change. This is one of the really powerful features of Meteor.\nThe work with the developer at the client last week has renewed my interest in Meteor and will have to dig into it more.\nIf you prefer to watch a video of this as well, check out Video – Deploying your Meteor app to Cloud Foundry and Bluemix.\nI would love to hear your feedback and any suggestions you have, please reach out to me on Twitter [@jsloyer](https://twitter.com/jsloyer target=). There will also be a video forth coming as well.\n","date":"2015-08-05T11:03:35-05:00","image":"https://www.jeffsloyer.io/post/deploying-your-meteor-app-to-cloud-foundry-and-bluemix/meteor_hu_29b08e086396b49b.jpg","permalink":"https://www.jeffsloyer.io/post/deploying-your-meteor-app-to-cloud-foundry-and-bluemix/","title":"Deploying your Meteor app to Cloud Foundry and Bluemix"},{"content":"Recently the company that owns development for Ubuntu (Canonical) just announced it is dropping support for lucid 64 which is Ubuntu 10.04 LTS. What does this mean for Cloud Foundry and the community buildpacks?\nWell nothing really but there is a couple gotcha\u0026rsquo;s you should know about.\nI have seen issues with the following buildpacks, this is not a comprehensive list but the ones I at least know about.\nPHP - https://github.com/cloudfoundry/php-buildpack.git\nStatic Build Pack - https://github.com/cloudfoundry/staticfile-buildpack.git\nThese issues are documented in a couple StackOverflow posts but we are going to go through what is causing it and how to fix it.\nStatic Buildpack\nStatic Buildpack\nIf you are pushing an app to Cloud Foundry and getting an error message like the following there is a workaround you need to do to get the community buildpack\u0026rsquo;s to work.\nFor example I have a super simple PHP app on Github I use for debugging, it is located here. For this blog post we are going to use that app.\n1 2 3 4 5 6 7 8 9 10 11 12 git clone https://github.com/jsloyer/phpinfo.git cd phpinfo cf push phpinfo-jbs2 -b https://github.com/cloudfoundry/php-buildpack.git ..... It looks like you\u0026#39;re deploying on a stack (currently set to *lucid64*) that\u0026#39;s not supported by this buildpack. That could be because you\u0026#39;re using a recent buildpack release on a deprecated stack. If you\u0026#39;re using the buildpack installed by your CF admin, please let your admin know you saw this error message. If you at one point specified a buildpack that\u0026#39;s at git URL, please make sure you\u0026#39;re pointed at a version that supports this stack. Staging failed: Buildpack compilation step failed FAILED BuildpackCompileFailed What this is saying is the instance of Cloud Foundry that you are running on the default stack you get is an old version of Ubuntu. The PHP buildpack excepts the newer version of linux. This stack is called cflinuxfs2 also known as Ubuntu 14.04.\nTo work around this you just need to specify the stack you want to use.\n1 cf push phpinfo-jbs2 -b https://github.com/cloudfoundry/php-buildpack.git -s cflinuxfs2 More information can be found on this issue on Github.\n","date":"2015-07-29T10:58:25-05:00","image":"https://www.jeffsloyer.io/post/cloud-foundry-php-buildpack-doesnt-support-lucid64/fedup_hu_c21e522d75dc93cd.jpg","permalink":"https://www.jeffsloyer.io/post/cloud-foundry-php-buildpack-doesnt-support-lucid64/","title":"Common Deploy Errors with Community Buildpacks in Bluemix"},{"content":"This is a part two post following up on my earlier post on Zero Downtime Deployment with the CF Autopilot Plugin. I highly encourage you to read the first part before reading this post but if you are lazy I will go over the high level concepts here.\nOverview of Part 1 (Quick Refresher) In part 1 we went over what a zero downtime deployment is and why it is in important. Let\u0026rsquo;s briefly cover that again.\nZero Down time deployments are basically what they sound like. You update production without taking downtime. It’s not always that simple though. For the context of this post we are going to be talking about how to do zero down time deployments in Cloud Foundry.\nBasically it’s a little trick to taking advantage of the way Cloud Foundry runs underneath the covers. Before we jump into it, there are a couple of caveats that we should discuss first. To successfully take advantage of zero down time deployments you should have followed the 12 Factor App guidelines. This will ensure that your app is horizontally scalable and can be deployed in a manner that will result in zero down time. Below are some highlights that you should abide by.\nDo not store sessions on disk or in memory. Store them in some type of shared database or file system. This could be your favorite database or an in memory database as well.\nDo not store configuration information in your application or on disk. You should store your config info for your app in environment variables.\nThis is probably the most important, your application needs to be forward and backwards compatible with your database schema… Say what? Yes, you need to trust your developers to manage the database schema from your code.If you are using a relational database, you will need some kind of framework to do database migrations for you. It’s not just that simple with relational databases though… If you have a big database migration DO NOT PERORM MIGRATIONS THAT WILL INTERRUPT TRAFFIC! Perform them slowly over time where migrations do not impact users and traffic. Yahoo had a major application upgrade and it took them 6 months to do the migration to avoid impacting users and taking an outage. Remember we do not take outages… If you are in NoSQL land, your life is easier. Just revision your API’s and educate your developers on forward and backwards data compatibility.\nImportance of Zero Down Time Deployments So why are zero down time deployments so important? The answer is simple, to keep your website/app up so you can make money! Well that might be over-simplified a bit, but basically it all boils down to keeping your app up so you can continue to do what you do best, and hopefully that involves making money. If you look at Facebook, for example, they put code into production weeks and months before a feature is exposed to the public. They extensively test the features on employees first, then slowly enable the features to the rest of the world. This is key, getting features in front of your customers and getting feedback from them. If it works that’s great, but if it doesn’t at least you know in a short time frame so you can remove it and pivot to go in a different direction. The current landscape is so fast paced that if you don’t get a feature out, your competition could beat you.\nHow does it work? So let’s walk through what needs to happen to perform zero downtime deployments in Cloud Foundry. For the use of the walk-through, the application is currently taking traffic on myapp.mybluemix.net.\nDeploy your app or use a currently running app. Currently your application is taking traffic on myapp.mybluemix.net. Deploy the new version of your app to myapp-temp.mybluemix.net. At this time there is currently two versions of your app running. myapp.mybluemix.net is still taking production traffic. The new app myapp-temp.mybluemix.net is separate, it can be pointed to your production API keys and databases at this point. Perform smoke tests on the new version of the application. Some people say this step is optional, but to me its not. This is key to make sure there wasn’t any weird regressions or merge issues, they CAN happen…\nMap production traffic to the new version of your app. At this point the old version of your app and the new version are both taking production traffic. Unmap production traffic from the old version of the app. You can optionally delete the old version as well. At this point the new version becomes production and ONLY it is taking traffic. The new version still has two URL’s though, myapp.mybluemix.net and myapp-temp.mybluemix.net. Remove the temporary route myapp-temp.mybluemix.net from the new version of your app. While this can be scripted there really isn’t a need to do that, there is a Cloud Foundry CLI plugin to do this.\nAutopilot plugin Recently the Cloud Foundry CLI started supporting plugins. This is the holy grail for CF and you can start doing some fun stuff. In this case, the fun stuff is automating the complex, possibly human error-prone, steps above. As a dev, if I can automate something and reduce the chance of something going wrong, I am all in. If you do this, your IT/operations department will love you.\nThe plugin performs the above steps for you for performing the zero downtime deployment.\nIn part 1 we deployed our application manually to Bluemix using the autopilot plugin locally, in this tutorial we are going to use Codeship to automate our continuous delivery pipeline to use the plugin to perform the zero downtime deployments.\nCodeship setup First make sure you have a Bluemix account, if you do not sign up by clicking Bluemix.\nSecondly make sure you have signed up for a Codeship account, to do this head here. When I signed up, I clicked \u0026ldquo;Sign up with github\u0026rdquo;, make sure you do this so Codeship can authenticate with your Github account.\nOnce you are signed in click \u0026ldquo;Setup new Project\u0026rdquo;, it will bring you a screen like below.\nClick on the button on the left. If you signed up with your Github account it will authenticate you with Github, if you haven\u0026rsquo;t you will need to connect your account to Github.\nOnce you have done this you will get a screen like below. Codeship will show you all the projects you have access to.\nClick on the repo you would like to use.\nYou will be then brought to a screen that ask you to setup your pipeline.\nFirst, we need to remove the test pipeline, lets click on \u0026ldquo;Delete\u0026rdquo;. If you had unit tests you could run them here, for example grunt.\nNext since this example is a Node.Js project, we want to make sure the node modules are correct, we want to run npm install here. We need to clear out the initial starter setup commands that have been highlighed below.\nIt should look like the following now.\nNote, if you are using a different language you would want to run the appropriate dependency installer here, for example for Java mvn install.\nLastly, click \u0026ldquo;Save and goto dashboard\u0026rdquo;.\nClick on \u0026ldquo;Project settings\u0026rdquo; in the top right, then click on \u0026ldquo;Environment variables\u0026rdquo;. You will be brought to a screen like the following.\nYou need to setup a couple environment variables to make this work.\nCF_API CF_SPACE CF_ORG CF_USERNAME CF_PASSWORD Below is a screen shot of things setup.\nNext, click deployment on the left and type in \u0026ldquo;master\u0026rdquo; without the quotes for the branch name and click \u0026ldquo;Save pipeline settings\u0026rdquo;.\nClick \u0026ldquo;Custom Script\u0026rdquo;.\nPaste in the following code, replace myapp with the name of your app. Note: This requires your app to have a manifest.yml\nIt should look like the following.\nClick \u0026ldquo;Create\u0026rdquo;.\nYou are all set. Next time you do a git push to Github your app will be auto deployed to Bluemix!\nI would love to hear your feedback and any suggestions you have, please reach out to me on Twitter [@jsloyer](https://twitter.com/jsloyer target=)\n","date":"2015-07-20T10:54:13-05:00","image":"https://www.jeffsloyer.io/post/zero-downtime-deployments-with-bluemix-and-codeship/unplug_hu_5a7d5a25d79328e0.jpg","permalink":"https://www.jeffsloyer.io/post/zero-downtime-deployments-with-bluemix-and-codeship/","title":"Zero downtime deployments with Bluemix and Codeship"},{"content":"I recently wrote a blog post on what a zero downtime deployment is, why it is important, and how to perform one. I am now posting a video on the same topic so you can learn about a zero downtime deployment by watching a video instead.\nIf you prefer the tutorial and text instructions please check out Zero Downtime Deployment with the CF Autopilot Plugin.\nI would love to hear your feedback and any suggestions you have, please reach out to me on Twitter [@jsloyer](https://twitter.com/jsloyer target=)\n","date":"2015-07-01T10:51:49-05:00","image":"https://www.jeffsloyer.io/post/zero-downtime-deployment-with-the-cf-autopilot-plugin-video/unplug_hu_5a7d5a25d79328e0.jpg","permalink":"https://www.jeffsloyer.io/post/zero-downtime-deployment-with-the-cf-autopilot-plugin-video/","title":"Zero Downtime Deployment with the CF Autopilot Plugin - Video"},{"content":"As announced yesterday, IBM has formed a partnership with Box.com, a partnership that includes the integration of Box into the Bluemix catalog. With its REST-based Content and View APIs, embedding enterprise-grade file storage into your app and enabling file sharing among your users has never been simpler.\nTo help you on your way to becoming a file-sharing guru, Bluemix developer advocate Jake Peyser and I have built a sample app that you can leverage as you begin to explore the possibilities of the Box.com APIs. The video below shows the application and outlines the steps to create it:\nIf you want to follow written step-by-step instructions on how we leveraged the Box.com and Watson Personality Insights services to create our app, see Integrate Cloud File Storage and Sharing into your Bluemix App with Box. We encourage you to pick up where we left off and build on this sample!\n","date":"2015-06-29T10:46:59-05:00","image":"https://www.jeffsloyer.io/post/personality-box-you-had-me-at-upload/box_hu_6fa95510d2ca8b7c.png","permalink":"https://www.jeffsloyer.io/post/personality-box-you-had-me-at-upload/","title":"Personality Box – You had me at upload"},{"content":"Zero down time deployments are a must for any Internet app running at scale. Without the use of zero down time deployments, you would have to take down your application even just for a fraction of a second but in that fraction of a second you could lose a transaction or a purchase from a customer. This is not acceptable anymore. Some people like to call these apps cloud based apps, which I think is fine, but I’d rather call them Internet scale or born on the cloud apps. The companies who create these apps understand the apps’s need to stay up, because their app is their only lifeline and, hopefully, a source of income from the world.\nCompanies such as Facebook, Etsy, and Twitter have been using zero down time deployments for years. They thrive because they do multiple deployments to production a day. The number of deployments they do in one day is actually larger than most enterprise companies do in a full year. Part of the trick is that the code changes are small but they have employed strategies such as zero down time deployments to get code into production as fast as they can.\nGround Rules… There are many names for this, zero down time deployments, obviously, but some people use the term blue/green, while others use the term red/back. They all mean the same thing. Instead of having a bias for colors in this post lets use the term “zero down time”.\nSo what is it?\nZero Down time deployments are basically what they sound like. You update production without taking downtime. It’s not always that simple though. For the context of this post we are going to be talking about how to do zero down time deployments in Cloud Foundry.\nBasically it’s a little trick to taking advantage of the way Cloud Foundry runs underneath the covers. Before we jump into it, there are a couple of caveats that we should discuss first. To successfully take advantage of zero down time deployments you should have followed the 12 Factor App guidelines. This will ensure that your app is horizontally scalable and can be deployed in a manner that will result in zero down time. Below are some highlights that you should abide by.\nDo not store sessions on disk or in memory. Store them in some type of shared database or file system. This could be your favorite database or an in memory database as well.\nDo not store configuration information in your application or on disk. You should store your config info for your app in environment variables.\nThis is probably the most important, your application needs to be forward and backwards compatible with your database schema… Say what? Yes, you need to trust your developers to manage the database schema from your code.If you are using a relational database, you will need some kind of framework to do database migrations for you. It’s not just that simple with relational databases though… If you have a big database migration DO NOT PERORM MIGRATIONS THAT WILL INTERRUPT TRAFFIC! Perform them slowly over time where migrations do not impact users and traffic. Yahoo had a major application upgrade and it took them 6 months to do the migration to avoid impacting users and taking an outage. Remember we do not take outages… If you are in NoSQL land, your life is easier. Just revision your API’s and educate your developers on forward and backwards data compatibility.\nImportance of Zero Down Time Deployments So why are zero down time deployments so important? The answer is simple, to keep your website/app up so you can make money! Well that might be over-simplified a bit, but basically it all boils down to keeping your app up so you can continue to do what you do best, and hopefully that involves making money. If you look at Facebook, for example, they put code into production weeks and months before a feature is exposed to the public. They extensively test the features on employees first, then slowly enable the features to the rest of the world.\nThis is key, getting features in front of your customers and getting feedback from them. If it works that’s great, but if it doesn’t at least you know in a short time frame so you can remove it and pivot to go in a different direction. The current landscape is so fast paced that if you don’t get a feature out, your competition could beat you.\nHow does it work? So let’s walk through what needs to happen to perform zero downtime deployments in Cloud Foundry. For the use of the walk-through, the application is currently taking traffic on myapp.mybluemix.net.\nDeploy your app or use a currently running app. Currently your application is taking traffic on myapp.mybluemix.net. Deploy the new version of your app to myapp-temp.mybluemix.net. At this time there is currently two versions of your app running. myapp.mybluemix.net is still taking production traffic. The new app myapp-temp.mybluemix.net is separate, it can be pointed to your production API keys and databases at this point. Perform smoke tests on the new version of the application. Some people say this step is optional, but to me its not. This is key to make sure there wasn’t any weird regressions or merge issues, they CAN happen…\nMap production traffic to the new version of your app. At this point the old version of your app and the new version are both taking production traffic. Unmap production traffic from the old version of the app. You can optionally delete the old version as well. At this point the new version becomes production and ONLY it is taking traffic. The new version still has two URL’s though, myapp.mybluemix.net and myapp-temp.mybluemix.net. Remove the temporary route myapp-temp.mybluemix.net from the new version of your app. While this can be scripted there really isn’t a need to do that, there is a Cloud Foundry CLI plugin to do this.\nAutopilot plugin Recently the Cloud Foundry CLI started supporting plugins. This is the holy grail for CF and you can start doing some fun stuff. In this case, the fun stuff is automating the complex, possibly human error-prone, steps above. As a dev, if I can automate something and reduce the chance of something going wrong, I am all in. If you do this, your IT/operations department will love you.\nThe plugin performs the above steps for you for performing the zero downtime deployment.\nEnsure you have a Bluemix account, if you do not sign up Bluemix.\nInstall dependencies.\n1. Golang installed ([instructions](https://golang.org/doc/install)) 2. Version 6.7.0 or greater of the Cloud Foundry CLI To check what version you have running, run `cf -v` in your terminal. [01:36 PM] jsloyer@jeffs-mbp-2 [~]\u0026gt;cf -v cf version 6.8.0-b15c536-2014-12-10T23:34:29+00:00 To upgrade go [here](https://github.com/cloudfoundry/cli/releases). Ensure you have an app running/already deployed. The plugin requires that you have an app already deployed.\nRun the following. I will describe what each line is doing.\ngo get github.com/concourse/autopilot cf install-plugin $GOPATH/bin/autopilot cf login -a ${CF_API} -u ${CF_USERNAME} -p ${CF_PASSWORD} -o ${CF_ORG} -s ${CF_SPACE} cf zero-downtime-push myapp -f manifest.yml\nLine 1 fetches the source code for the plugin. Line 2 installs the plugin Line 3 logins into Bluemix. I have the sensitive information replace with environment variables. Line 4 performs the zero down time deployment. The plugin does require a manifest.yml. The plugin basically views the manifest.yml files as the truth of the state of the application.\nExtensions with CI Pipelines This will be forthcoming in an upcoming blog post on how to use some of the most popular CI engines out there.\nRecap Just to review what we did here, we learned what zero down time deployments are, why they are crucial to any Internet scale application, and how to perform a zero down time deployment. Then, we took it a step further on how to use a Cloud Foundry plugin to do the heavy lifting for us and automate the zero down time deployment.\nI would love to hear your feedback and any suggestions you have, please reach out to me on Twitter [@jsloyer](https://twitter.com/jsloyer target=)\nVideo I have also published a video if you prefer to watch that instead, please check out Zero Downtime Deployment with the CF Autopilot Plugin – Video.\nAdditional part\u0026rsquo;s Zero downtime deployments with Bluemix and Codeship ","date":"2015-06-19T10:41:59-05:00","image":"https://www.jeffsloyer.io/post/zero-down-time-deploys-with-the-cf-autopilot-plugin/unplug_hu_5a7d5a25d79328e0.jpg","permalink":"https://www.jeffsloyer.io/post/zero-down-time-deploys-with-the-cf-autopilot-plugin/","title":"Zero Downtime Deployment with the CF Autopilot Plugin"},{"content":"I’m pumped for the Cloud Foundry Summit! Are you??? Well if you aren’t yet hopefully you will be after reading this!\nIf you attended the conference last year there was an awesome presentation on the future of Diego. What is Diego you ask? It is the new DEA that is coming for Cloud Foundry. It is a complete re-write in Go and will add some new features such as the ability to swap out the underlaying linux containers for things like Docker. Additionally another huge win is adding in plugins, this will be awesome as well!\nAdditionally, there is always a cast of characters there… Angel Diaz (from IBM) is a great speaker and always pumps people up (literally). You should ask him to arm wrestle you, I would lose…\nOk so for reals, what am I really excited about, well the tech, duh… Here is a list of some of the sessions I am really pumped about and why.\nSessions A Developer’s Perspective on Cloud Foundry Operations: One Month in the Trenches by Cornelia Davis — Well this one is pretty obvious why, Cornelia is an awesome speaker and I am never let down by her talks, must see just for her.\nRocking the Lattice: A New Path for Cloud Foundry Applications by James Bayer — Again probably the same reason as above, James is an awesome speaker and a must see\nCase Study: Lessons learned hosting a large, global Cloud Foundry deployments by Adam Gunther — This should be a good one, hosting and running a large scale Cloud Foundry deployment isn’t easy it will be interesting to learn some lessons learned. Plus Adam is my new manager so I should probably show up so he has a plant in the audience…\nA glimpse at Runtime by Zachary Auerbach and Daniel Lavine — The runtime is probably the most important part of Cloud Foundry and its always nice to hear and see some of the inner workings of the runtime team, a must see…\nThe Road to Persistence on Cloud Foundry Diego by Caleb Miles and Ted Young — This will be a good one, this talk is going to talk about a new model for the 12 factor app and more specifically some cool cluster scheduling systems like Apache Mesos. I have friends at Twitter and the swear up and down on Mesos and how awesome is it.\nFinding and Organizing a Great Cloud Foundry User Group by Daniel Krook, Manuel Silveyra and Animesh Singh — Cloud Foundry wouldn’t be successful without its community. These guys are going to be talking about how they have run and organized some of the most successful Cloud Foundry meetups in the Bay Area and NYC.\nAgain, get PUMPED!!! I am all jacked up and ready to head to the CF Summit, better see you there. If you come up to me at the Summit and yell out get pumped in front of me, I’ll buy you a beer or something…\n","date":"2015-04-30T10:38:05-05:00","image":"https://www.jeffsloyer.io/original-images/2015/06/8568353810_30fa30c147_o.jpg","permalink":"https://www.jeffsloyer.io/post/get-pumped-for-the-cloud-foundry-summit/","title":"Get Pumped for the Cloud Foundry Summit"},{"content":"This is an extension/continuation from the blog post on how to create a basic Python webapp. In this tutorial we are going to go through how to integrate a Python Flask webapp in Bluemix with the Internet of Things Foundation in Bluemix with a Raspberry Pi and two sensors on the Raspberry Pi. The tutorial also uses Twilio to interact with the Raspberry Pi.\nSo what does this look like? Here is a simple architecture diagram.\nIn the above diagram there is two flows:\nThe first flow involves pressing a HTML button in the Python Flask app in Bluemix to either turn on or off an LED on the Raspberry Pi.\nThe second flow involves pressing a physical button on the breadboard on the Raspberry Pi and using the IoT service in Bluemix and our app in Bluemix it will send a text message of our choosing to a phone number we enter in the Python Flask app in Bluemix using Twilio.\nThis all took only about 100 lines of code, pretty cool huh?\nIf you prefer to watch a video of this instead of going through the written steps in this tutorial, check out the video below.\nSetup There is two parts to setting this up. If we take a look at the architecture diagram above we see that there is a Raspberry Pi piece and then a Bluemix piece. We are going to go through the Raspberry Pi piece first then we will go through the Bluemix piece.\nRaspberry Pi Setup Steps Sign up for a Bluemix account, visit http://bluemix.net in your web browser and click “Sign-up” in the top right. We require a couple bits of information\nWait for an email to arrive, it should only take a couple minutes. There should be a link in the email that says “Click here to complete your registration”, click that. Sign in with the username and password you created from step 1.\nObtain a Raspberry Pi, a bread board, wires, a LED, and a button (your best bet is getting a starter kit such as the Canakit)\nPlace an LED in the breadboard (place the shorter side to the left)\nPlace a 220 ohm resistor in the breadboard connecting the short side (the left side of the LED) to the ground rail (the rail with the – sign). Make sure to place the side of the resistor with the red stripes closest to the LED_NOTE:_ The way the breadboard works is connections run vertically not horizontally\nConnect a wire from the ground rail to the GND on the pinout board\nOn the right side of the LED, connect a wire to the the port labeled 17.NOTE: The way the breadboard works is connections run vertically not horizontally.\nPlace the button in the breadboard, it takes a bit of force to press it in all the way. It won’t break it.\nConnect a wire from the right side of the button to the ground rail.\nConnect a wire from the ground rail to a GND port, it doesn’t matter which one it is\nLastly, connect a wire from the left side of the button to GPIO port 18.\nNext we need to either use the console for our Raspberry Pi and the terminal application on the device itself or use SSH. I am going to use SSH.\nTo get the IP address of your Raspberry Pi the easiest thing is to open up the terminal app on the Raspberry Pi, it is under accessories -\u0026gt; Terminal\nType ifconfig.. If you are connected over Ethernet the IP address will be under eth0, if you are connected over wifi, the IP address will be under wlan0\nNext we need to ssh into the device.—Windows, download Putty and use that to connect to the IP address—Mac and Linux, open the Terminal app, type ssh pi@myipaddress where myipaddress is the IP address of the Raspberry Pi, ex. 192.168.1.65\nThe password is raspberrypi\nWe need to run some commands to update our Raspberry Pi, run the following. It will ask you to confirm with the “Y” key\nsudo apt-get update sudo-apt-get upgrade\nNext we need to install a helper library for using GPIO\ngit clone git://git.drogon.net/wiringPi cd wiringPi ./build\nNext we need to install the IoT library on the Raspberry Pi\ncurl -LO https://github.com/ibm-messaging/iot-raspberrypi/releases/download/1.0.2/iot_1.0-1_armhf.deb sudo dpkg -i iot_1.0-1_armf.deb\nWe need to get the device ID of our raspberry Pi do this run the following and save the output\nservice iot getdeviceid #example output The device id is b827eba5b236\nWe will want to copy the id `b827eba5b236`, yours obviously will be different Open up a web browser and goto bluemix.net, and click on “Catalog” in the top. Scroll down to the very bottom and click “Internet of Things”.\nGive the service a name, use iot-python (you must do this exactly or later things won’t work), for App choose “Leave unbound”, click “Create”.\nOn the left of the next page click “Launch dashboard”.\nAt the top click on “Devices”.\nClick “Add Device”.\nFor the second field (it says e.g. mydevice type) type in exactly raspberrypi (you need to have it spelled like this or there will be issues). For device ID paste in the device ID we got from step 20, mine is b827ba5b236. Click continue.\nOn the next page it will show something like below, copy this and switch back to terminal on your Raspberry Pi.\norg=pwftki type=raspberrypi id=000000000000 auth-method=token auth-token=cXQaGx8o!a9HwxM-ka\nChoose your favorite text editor but I am going to use vi. Type the following to open the file we want to edit.\nsudo vi /etc/iotsample-raspberrypi/device.cfg\nTo paste the text press the “i” key. Then paste the text, this will depend on the OS you are on.\nTo save the file hit the “Esc” key. Then Type “:wq” and then press “Enter”. That will save the file.\nLet’s restart the IoT service on our Raspberry Pi to start sending the data to the IoT service\nsudo service iot restart\nNext we need to download the Python code to run on the Raspberry Pi, run the following:\ncd ~ git clone https://github.com/IBM-Bluemix/python-iot-raspberry-pi.git cd python-iot-raspberry-pi\nNow we need to install the package manager for Python:\nsudo apt-get install python-pip sudo pip install -r requirements.txt\nOne last bit, we need a config file for our app before we can start it. Lets run the following:\nvi ~/device.cfg\nRemember this is vi again, so remember the shortcuts for inserting text and saving it from step 29,30. The contents of the file should look something like below, replacing yourapikey, yourdeviceid, youriotorg, and yourapitoken with the correct values. To generate the API key and token we can get them from going back to the web browser and going to the Internet of Things Foundation. At the top click on API Keys. Click “New API Key”. The values that it gives you will be the values you use for the yourapitoken and yourapikey. yourdeviceid is the value we got from step 20 youriotorg is from step 27, it is also in your config file; in my case my value is pwftki. Let’s save the file (remember, “Esc”, “:wq”, “Enter”)\n[application] org=youriotorg id=yourdeviceid auth-method=apikey auth-key=yourapikey auth-token=yourauthtoken\nOK, so now we can launch/start the app on the Raspberry Pi. To do that run the following:\ncd ~/python-iot-raspberry-pi sudo python client.py\nBluemix App Setup Steps NOTE: The following steps are to be run on your desktop NOT the Raspberry Pi. We will need to install the Cloud Foundry CLI to deploy our app to Bluemix. To do this head over to https://github.com/cloudfoundry/cli/releases. Choose the appropriate installer for your platform, download it and run the installer.\nSo let’s open up a new terminal Window, we will need to do the rest on our development machine/laptop.\nWe need to download the Python code for our app. Run the following. If you don’t have git installed follow these instructions here.\ngit clone https://github.com/IBM-Bluemix/python-iot-raspberry-pi.git cd python-iot-raspberry-pi\nIn your web browser go back to the tab that you have Bluemix open with. In the top click “Catalog”, scroll down to find “Twilio”. Click on that.\nIf you already have a Twilio account and want to use that skip to step 6. If you don’t have a Twilio account on the right hand side click “Register at Twilio”.\nTwilio will ask you for some information and you will need to verify your phone number. This is important as only numbers verified with the free plan will work with your app. If you want to be able to text any number you need to pay for Twilio, its $1/month/phone number.\nOnce you are signed up for your account, head to https://www.twilio.com/user/account/voice-messaging. Near the top right there will be a twistie that says “Show API Credentials”, click that. There is two pieces of information here, the Account SID and Auth Token. We will need to copy these back to the Bluemix tab we have open with Twilio.\nPaste your Account SID in the field in Bluemix that says Account SID, paste your Auth Token in the Auth Token field.\nFor the Service name you must type in this exactly iot-twilio\nFor the App, choose “Leave Unbound”\nClick Create.\nSwitch back to the terminal that you have on your local dev machine, not your Raspberry Pi.\nWe need to login to Bluemix, to do that, type cf login -a https://api.ng.bluemix.net. It will ask you for your username and password. This is from step 1 in the Raspberry Pi section above.\nTo deploy our application all we need to do now is type cf push myappname where myapp name is a unique name you choose for your app.NOTE: If you get an error mentioning a route is taken, choose a different name and run cf push with a new app name.\nIt will take about a minute or two to deploy your application but eventually you will get some output that looks like the following:\nrequested state: started instances: 1/1 usage: 1G x 1 instances urls: testapp-jbs.mybluemix.net last uploaded: Fri Jul 31 00:25:17 UTC 2015 stack: lucid64 buildpack: SDK for Node.js(TM) (ibm-node.js-0.12.7)\nThere is a row that says urls:, copy that URL and paste it into your browser.\nIf everything went well you should have a page that looks like the following:\nAn important note here, do not press the button on the Raspberry Pi until you enter a phone number and text message here, if you do the app will crash. If you do this you can restart you app with cf restart myappname, where myappname is the name of the app you chose above.\nWhen you click the “On” button it should turn the light on for you. If you press the “Off” button it should turn the light off.\nFeedback Follow us on Twitter at @IBMBluemix and follow the author of this blog post (Jeff Sloyer, one of our developer advocates) at @jsloyer\n","date":"2015-04-02T10:29:53-05:00","image":"https://www.jeffsloyer.io/post/iot-python-app-with-a-raspberry-pi-and-bluemix/iot-pi_hu_c633188902e28001.jpg","permalink":"https://www.jeffsloyer.io/post/iot-python-app-with-a-raspberry-pi-and-bluemix/","title":"IoT Python app with a Raspberry Pi and Bluemix"},{"content":"Hey Y’all! Jeff here again, today we are going to be going through some really simple steps to get started deploying a simple hello world python app using Flask on Bluemix.\nFlask is an awesome and really lightweight framework in Python to create powerful webapps. We are going to use it make a really simple hello world app in Python though.\nIn this post we are going to go through the written instructions on how to do it but if you prefer watching a video check out the video below.\nIn this tutorial we are going to go through two steps to deploy the app. One is a simple click a button to deploy to your app, we will go through that first. The second approach is a little more in depth and involves installing a command line tool to upload the application. This is great and preferred if you will be editing the code or you want to dig into the nuts and bolts of things.\nSimple Getting Started Steps Sign up for a Bluemix account, visit http://bluemix.net in your web browser and click “Sign-up” in the top right. We require a couple bits of information\nWait for an email to arrive, it should only take a couple minutes. There should be a link in the email that says “Click here to complete your registration”, click that. Sign in with the username and password you created from step 1.\nClick the button below (this will deploy the app for you).\nYou will come to a page that has a button called “Login”. Go ahead and click that.\nNext you will be taken to a page that asks you to create an alias. If my email address was jeff.davis251@gmail.com I would use jeffdavis251. Hint it doesn’t like periods Click Create.\nIt will take you to another page, click “Continue”.\nNow everything is basically setup, it will take us to a page that looks like what is below, just click the “Deploy” button.\nGrab a cup of coffee or take a bathroom break, well a quick one! It will only take a minute or two to deploy the app.\nIn a hot second you should be taken to a page that looks like what is below. To view your hello world app just click the button “View your App”. [![deploy done 1024x544 Simple Hello World Python App using Flask]\nThats it for the quick and easy steps. Let’s go through the more advanced steps where you can modify the code and upload the app from your own machine.\nA little more involved steps This will assume you have signed up for an account, steps 1 and 2 from above. If you haven’t signed up for an account scroll up and do that now.\nInstall Git, follow the instructions from here.\nInstall the Cloud Foundry command line. Choose the appropriate installer from here and download it and run the installer. You might be asking what Cloud Foundry is, its the open source Platform as a Service that Bluemix is built on.\nOpen up the terminal/command prompt Mac – Click on the finder icon in the top right, search for terminal and open that Linux – Depends on your distro, but you probably know where it is, in the menu look for accessories usually then terminal, open that Windows – Click the start button, search for cmd, open that\nType the following. The following commands downloads the starter app and puts us into the right directory to deploy the app.\ngit clone https://github.com/IBM-Bluemix/python-hello-world-flask.git cd python-hello-world-flask\nNext we need to login to Bluemix, we will use the terminal window that we already have open for this.\ncf login -a https://api.ng.bluemix.net\n__Note__: It will ask for your username and password, this is the one you just created. Last step, we just need to upload the app, run the following replacing myappname with the URL you want your app to be available at. Bluemix will give you a URL based on this name. If I chose jeff-is-awesome, my app would be available at http://jeff-is-awesome.mybluemix.net.\ncf push myappname\nIf you get an error mentioning something like below, that means someone already has an app using that URL, just choose another one and rerun the command\nError: 1 2 3 4 5 6 7 [01:54 PM] jsloyer@Jeffs-MacBook-Pro [python-hello-world-flask]\u0026gt;cf push jeff-is-awesome Creating app jeff-is-awesome in org jbsloyer@us.ibm.com / space demos as jbsloyer@us.ibm.com... OK Creating route jeff-is-awesome.mybluemix.net... FAILED Server error, status code: 400, error code: 210003, message: The host is taken: jeff-is-awesome Fix: 1 cf push myappname-unique You will basically get some output that looks like the following. It will give you the URL to access your app. In this case the URL to my app is http://jeff-is-awesome2.mybluemix.net.\n1 2 3 4 5 6 7 8 [02:05 PM] jsloyer@Jeffs-MacBook-Pro [python-hello-world-flask]\u0026gt;cf push jeff-is-awesome2 Updating app jeff-is-awesome2 in org jbsloyer@us.ibm.com / space demos as jbsloyer@us.ibm.com... ... snip ... App jeff-is-awesome2 was started using this command `python hello.py` Showing health and status for app jeff-is-awesome2 in org jbsloyer@us.ibm.com / space demos as jbsloyer@us.ibm.com... Wrapping Up To recap we just went through two different ways to deploy a python app to Bluemix. The first method is really quick so you can see the power of the platform and get something up and running quick. The second approach used the command line so you can modify the app and hack on it and customize it.\nFeedback Follow us on Twitter at @IBMBluemix.\nFollow the author of this blog post (Jeff Sloyer, one of our developer advocates) at @jsloyer\n","date":"2015-03-30T10:17:51-05:00","image":"https://www.jeffsloyer.io/post/simple-hello-world-python-app-using-flask/helloworld_hu_d5fb3643934d702e.png","permalink":"https://www.jeffsloyer.io/post/simple-hello-world-python-app-using-flask/","title":"Simple Hello World Python App using Flask"},{"content":"Who doesn’t love some Ruby? Bluemix definitely loves Ruby on Rails! Sometimes running a Ruby on Rails app can be a little tricky, so I have included some tips and tricks for migrating your Ruby on Rails app to Bluemix. They will include:\nRequired gems Code tweaks Accessing external databases Deploying your app Required gems If you are using PostgreSQL you need to include pg. Sqlite3 is included to get local development working as well. Add the following line to your Gemfile.\n1 2 gem \u0026#39;pg\u0026#39; gem \u0026#39;sqlite3\u0026#39; Additionally there are two more gems you should include as well. These gems will be included by some Ruby buildpacks but we should include them just in case.\n1 2 gem \u0026#34;cf-autoconfig\u0026#34;, \u0026#34;~\u0026gt; 0.2.1\u0026#34; gem \u0026#39;rails_12factor\u0026#39;, group: :production Code tweaks \u0026amp; external databases When you deploy your app to Bluemix, the Ruby buildpack will overwrite your database.yml file to pull in the attached DB service. You should have a database.yml file if you are running locally. Below is a pretty standard one:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # SQLite version 3.x # gem install sqlite3-ruby (not necessary on OS X Leopard) development: adapter: sqlite3 database: db/development.sqlite3 pool: 5 timeout: 5000 # Warning: The database defined as \u0026#34;test\u0026#34; will be erased and # re-generated from your development database when you run \u0026#34;rake\u0026#34;. # Do not set this db to the same as development or production. test: adapter: sqlite3 database: db/test.sqlite3 pool: 5 timeout: 5000 production: adapter: sqlite3 database: db/production.sqlite3 pool: 5 timeout: 5000 If you are using Redis and PostgreSQL, it can be a little tricky to use two databases. Here is the config for using Redis with Resque (a task scheduler that is backed by Redis). This file is specific to resque and its located at config/initializers/resque.yml.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 require \u0026#39;resque/status_server\u0026#39; require \u0026#39;json\u0026#39; rails_root = ENV[\u0026#39;RAILS_ROOT\u0026#39;] || File.dirname(__FILE__) + \u0026#39;/../..\u0026#39; rails_env = ENV[\u0026#39;RAILS_ENV\u0026#39;] || \u0026#39;development\u0026#39; resque_config = YAML.load_file(rails_root + \u0026#39;/config/resque.yml\u0026#39;) if rails_env != \u0026#34;production\u0026#34; Resque.redis = resque_config[rails_env] else vcap_services = JSON.parse(ENV[\u0026#39;VCAP_SERVICES\u0026#39;]) credentials = vcap_services[\u0026#34;rediscloud\u0026#34;][0][\u0026#34;credentials\u0026#34;] Resque.redis = \u0026#34;:\u0026#34; + credentials[\u0026#34;password\u0026#34;] + \u0026#34;@\u0026#34; + credentials[\u0026#34;hostname\u0026#34;] + \u0026#34;:\u0026#34; + credentials[\u0026#34;port\u0026#34;] end Deploy your app! To deploy your app, you need to create some services in Bluemix for your app. We will do this with the Cloud Foundry command line.\nPostgreSQL:\n1 2 cf create-service elephantsql turtle postgres-myapp #postgres-myapp is the name of your service, you can name this whatever you want Redis:\n1 2 cf create-service rediscloud 25mb redis-myapp #redis-myapp is the name of your service, you can name this whatever you want Prepare your app Cloud Foundry requires a file called manifest.yml to help bind services to your app and defining memory limits, CPU limits, and the number of instances required. Belows is an example file I used. The name of the app is the unique identifier of your app that will be in your account. Hostname is the hostname of the app, it will be yourhostname.mybluemix.net or if you are running in London it will be yourhostname.eu-gb.mybluemix.net. The command is pretty important, it says it will run the db:setup everytime the app is deployed, this should probably be changed to db:migrate instead though.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 --- applications: #swap out myapp-jbs for your own app name - name: myapp-jbs memory: 1GB instances: 1 path: . command: bundle exec rake db:setup \u0026amp;\u0026amp; bundle exec rails s -p $PORT services: #swap out the below for your own #cf cs elephantsql turtle yourownname #cf cs rediscloud 25mb yourownname #redis cloud has different plans, check out cf marketplace for the plans - postgres-myapp - redis-myapp Push your app So we are on the final step, time to push our app! If you are using Ruby 2.2.0, it’s not officially supported by Cloud Foundry, but there is a buildpack that is part of the Cloud Foundry community github that we can use. It tracks pretty close to the latest Ruby and Rails. For my app I used Ruby 2.2.0 and Rails 4.2.0:\n1 cf push -b https://github.com/cloudfoundry/ruby-buildpack.git One last little tip… One last little tweak if you are familiar with Git it will make your life in Cloud Foundry land a little better. There is a file called .cfignore that goes in the root of your project, it basically acts like .gitgnore and prevents files being updated to Cloud Foundry. So for Ruby on Rails you probably would want your vendor folder here and etc. I have put one below that I use.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 .DS_STORE # Ignore bundler config /.bundle # Ignore the default SQLite database. /db/*.sqlite3 # Ignore all logfiles and tempfiles. /log/*.log /tmp # Ignore coverage /coverage # Tag file tags .idea/ .swo .swp .envrc cscope* doc/* .jira-url vendor/* If you have any issues please reach out to us on StackOverflow! In the top righthand corner click “Ask Question”.\n","date":"2015-03-05T10:09:31-05:00","image":"https://www.jeffsloyer.io/post/tips-for-migrating-ruby-on-rails-applications-to-bluemix/migrate_hu_b6775d9350c61c0d.jpg","permalink":"https://www.jeffsloyer.io/post/tips-for-migrating-ruby-on-rails-applications-to-bluemix/","title":"Tips for Migrating Ruby on Rails Applications to Bluemix"},{"content":"Part 2: Configuring the Raspberry Pi This is a continuation of Part 1 of Controlling home devices with Bluemix Internet Of Things If you haven’t read Part 1, please do that first…\nIn Part 1 we got the electrical work out of the way. We wired up the relay’s and connected the circuit’s. In this part of the 3 part series we will configure the Raspberry Pi to control the relay’s that we wired up in part 1.\nSo without delay let’s jump into the next part.\nInstall software on the Raspberry Pi The first step of getting your Raspberry Pi setup is installing Raspbian. If you have the Canakit its pretty easy, just plug in the wifi dongle and insert the SD card and plug in power. If you don’t have the Canakit follow the instructions from here. Once you get Raspbian installed open up a terminal.\nNext, we will need to update Raspbian to the latest. To do this run the following.\n1 2 sudo apt-get update sudo apt-get upgrade Next, we will need to download LightShowPi. LightShowPi is the foundation for syncing the lights to the music.\n1 2 3 4 5 6 7 8 9 10 11 12 # Install git (if you don\u0026#39;t already have it) sudo apt-get install git-core # Clone the repository to /home/pi/lightshowpi cd ~ git clone https://togiles@bitbucket.org/togiles/lightshowpi.git # Grab the stable branch cd lightshowpi git fetch \u0026amp;\u0026amp; git checkout stable Next, we need to install LightShowPi, run the following. Please not the install step will take some time, be patient…\n1 2 cd /home/pi/lightshowpi sudo ./install.sh Once the install is complete we need to reboot the Raspberry Pi to pickup some new environment variables. To reboot run the following.\n1 sudo reboot Wire up the Raspberry Pi’s breadboard Once we have rebooted we need to connect the bread board to the Raspberry Pi and connect the bread board to the relays. This took some tinkering to figure out the GPIO ports but below I have posted a picture of mybread board on how it was constructed. For me I set everything up with 8 channels first and using LED’s provided in the Canakit to make sure everything was working then I moved over to the real relays. So let’s do that.\nI would highly recommend following the steps in this page on getting your bread board working.\nBelow is a picture of my finished bread board with 16 channels. I have included a wiring diagram as well. Basically each GPIO port goes to the input side of the relay controller. If you notice I have a couple left over LED’s on the bread board, this was done via the tutorial list above.\nWhat is going on above is each of the delays is plugged into a GPIO port and then plugged into the ground rail and connected by a resistor. The particular resistor I am using is a 220 Ohm resistor.\nSo let’s test some things out. Let’s play a pre-loaded song.\n1 2 cd ~/lightshowpi sudo python py/synchronized_lights.py --file=/home/pi/lightshowpi/music/sample/ovenrake_deck-the-halls.mp3 All the relays should be flashing. At this point you can plug the lights into the outlets as well. If you notice the lights go on solid for 30 seconds before the songs play, we can override this. Additionally this file has the GPIO pins mapping as well. This mapping is for using the full 16 channels, if you are using less just remove some of the mappings from the end of the gpio_pins line. To do this we need to place a config file in our home directory.\n1 2 cd ~ touch .lights.cfg Choose your favorite text editor and put the following contents in the file. We change the time it waits from 30 seconds to 1.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 [hardware] gpio_pins = 0,1,2,3,4,5,6,7,21,22,23,24,25,26,28,29 [lightshow] preshow_configuration = { \u0026#34;transitions\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;on\u0026#34;, \u0026#34;duration\u0026#34;: 1, \u0026#34;channel_control\u0026#34;: { } }, { \u0026#34;type\u0026#34;: \u0026#34;off\u0026#34;, \u0026#34;duration\u0026#34;: 1, \u0026#34;channel_control\u0026#34;: { } } ] } That is it for this part. In the next part of this series we will configure the Bluemix app to respond to text message votes and then the app to interface with the python code that controls the lights.\nParts in the Series Part 1 ","date":"2015-02-17T10:02:18-05:00","image":"https://www.jeffsloyer.io/post/control-home-devices-with-bluemix-internet-of-things-part-2/robots-blog-post-header1_hu_4602de5065981a77.jpg","permalink":"https://www.jeffsloyer.io/post/control-home-devices-with-bluemix-internet-of-things-part-2/","title":"Control home devices with Bluemix Internet of Things (Part 2)"},{"content":"The number of Internet connected devices is growing dramatically, it is expected to increase from 15 billon devices in 2015 to 40 billion devices in 2020. These devices make up something called the Internet of Things. These devices can be controlled remotely and interconnected.\nWhile a lot of these devices can be connected to the Internet, most of them are \u0026ldquo;dumb\u0026rdquo; devices right now. To turn these \u0026ldquo;dumb\u0026rdquo; devices into smart devices you can use the Internet of Things to connect them to the cloud. Simple things such as a washing machine or a coffee pot can be connected to the Internet. More practical systems can be connected also, such as a home automation system or a thermostat. Going even further a mine could connect safety sensors to the Internet of Things as well.\nThe Internet of Things allows for these devices to either be controlled or act as sensors and provides a means for them to communicate. This is done over a protocol called MQTT. According to mqtt.org, \u0026ldquo;MQTT is a machine-to-machine (M2M)/Internet of Things connectivity protocol. It was designed as an extremely lightweight publish/subscribe messaging transport.\u0026rdquo; This works great for many devices as-is, doesn’t have many dependencies, it is very lightweight, and doesn’t require tremendous amounts of processing power.\nIBM Bluemix provides a platform for creating these apps that utilize all these sensors. You can basically almost use any programming language you want, Bring Your Own Language (BYOL) and utilize services that do the heavy lifting for you. This heavy lifting is the Internet of Things (IoT) service in Bluemix. It implements that MQTT protocol and allows you to control and receive data from these devices.\nDo you have a bunch of left over Christmas lights sitting around that will be collecting dust till next year? Until now Christmas lights are a once a year thing, that isn’t true anymore. Time to get the dust off of your lights and use them for something fun! Enter Christmas Lights controlled by a Raspberry Pi via IoT in Bluemix!\nYou can control these Christmas Lights using the Internet of Things and IBM Bluemix. Who doesn’t love large amounts of Christmas lights? I sure love them. Add on to that syncing lights to music and the ability to control lights from your phone and giving passersbys the ability to vote for songs they wanna see the lights synced to by texting. How cool is that?\nIntroduction: This is going to be a three part series: The first part (this post) will focus on the hardware setup, all the wiring and connecting things up to the Raspberry Pi. The second part will focus on the software configuration of the Raspberry Pi, and the final part will focus on the Bluemix app that allows people to vote on songs to play and the integration to control the Raspberry Pi with the IoT service in Bluemix.\nSo some of our goals that we are going to accomplish are the following.\nPart 1 – Setup and wire together relays, outlets, and the Raspberry Pi\nPart 2 – Power on the Raspberry Pi, installed Raspbian (OS for the Pi), install and configure the lighting control software\nPart 3 – Deploy a Bluemix app with the IoT, Twilio, and Cloudant services to interact with users and the Raspberry Pi (an example of the app is http://lights.mybluemix.net/; please note this is not connected to my Raspberry Pi right now, so clicking the play button won’t do anything.)\nHere is a little teaser of the expected outcome:\nLet’s jump into it…\nPart 1: Setting up the hardware These instructions have been adapted from the following sites.\nhttps://chivalrytimberz.wordpress.com/2012/12/03/pi-lights/\nhttps://docs.google.com/document/d/1x97JIu5xVInZMutTNeaHlnQuyoLHjf3h-ugIo64pGfI\nhttp://lightshowpi.org/download-and-install\nhttp://lightshowpi.org/configuring-and-testing-your-hardware\nhttp://lightshowpi.org/play-music\nThe first step is getting a Raspberry Pi, I highly recommend getting the CanaKit on Amazon. It comes with most of everything you will need. Depending on how fancy and clean you want your wiring to look you will need to take a trip to your local hardware/electrical store, more on that later.\nThe first step is deciding how many individual light channels you want—you can do up to 48 actually, but for this post we will doing 16 channels. What that means is 16 individual strands of lights that can be controlled. So let’s make a shopping list.\nShopping List:\n8 two gang outlets\n2 4 gang blue plastic outlet boxes\n50 feet of 12 gauge electrical wire\n2 bags of assorted wire nuts\n2 relays (1 relay per each 8 light channels, available on Amazon)\n1 powerstrip\n2 electrical extension cords\n16 strands of Christmas lights\nTools Required:\nWire Stripper\nScrew Drivers, phillips and flat\nMultimeter -optional\nMy brother (@esloyer) helped me wire this whole thing up and came up with an adapted wiring schema based off the sites above, thanks bro!\nOnce you get all the items on the shopping list we need to start taking apart the 50 feet of wire, there is 2 wires inside of the casing, a black and then a white one. We need to get them out of the casing, take a pocket knife or utility knife and make a cut into the casing at one end, you can basically then peal back the casing on the whole 50 feet of wire then.\nBelow is a wiring diagram that we need to complete. You can do this multiple ways but below is a suggestion.\nWhat we need to do is basically daisy chain all the \u0026ldquo;hot\u0026rdquo; wires together between each set of 4 gang double gang outlets. We do this so we don’t overload a particular circuit. So to do this we need to cut the end off of our cheap extension cord that has a plug on it, we need to then strip the wires, and then identity which wire is the hot/positive wire. Below is a picture of a wire, the hot/positive wire will have dashes or stripes on it, the cold/neutral wire will NOT have any dashes or stripes:\nWe need to take the hot wire and put it into a wire nut. We will then take some wire from our 50 feet, strip one of the ends and twist it into the wire nut. This will get attached to positive input on the relay. We need to repeat this for each channel. In the picture below I have an additional wire going from the first wire nut to another wire nut because all the wires going to the relay wouldn’t fit into one wire nut. We are just effectively connecting two wires together here.\nThe next step is running a wire from each channel on the relay to electrical outlet. This is the hot wire to each outlet but this wire is being controlled by the relay. Think of the relay as a simple on/off switch that you would find at home to control a light. On most double electrical outlets there is a tab on the side that comes enabled that makes most receptacles operate as one, this is desirable in a house so an electrician only has to run one wire to the outlet but in our case we want to take advantage of controlling both receptacles. We need to break this tab on both sides of the outlet. Take a pair of needle nodes pliers and bend the tab back and forth and eventually it will come off. See the photos below.\nBefore:\nAfter:\nSo next we need to connect our cold/negative wires to each of the outlets. If you look at the wiring diagram (above) I have one cold/neutral wire going to the first outlet and each additional outlet is daisy chained to it. This is just to complete the circuit. Below is the finished product. We basically have our outlets daisy chained together with our cold/neutral wires and then hold/positive wires have individual channels to the relay.\nCongratulations the hard part is over! Well, at least for me, since electrical stuff isn’t my forte.\nParts in the Series Part 2 ","date":"2015-02-06T09:49:21-05:00","image":"https://www.jeffsloyer.io/post/control-home-devices-with-bluemix-internet-of-things/robots-blog-post-header1_hu_4602de5065981a77.jpg","permalink":"https://www.jeffsloyer.io/post/control-home-devices-with-bluemix-internet-of-things/","title":"Control home devices with Bluemix Internet of Things"},{"content":"The State of the Union, a live broadcast that many Americans historically use as a tool to form opinions about the current political system, and gain insight from their Commander in Chief into the transparency of a system of checks and balances. What is more interesting is the thoughts and underlying feelings between the State of the Union. If we could figure out how the President is feeling or portraying himself, could we infer how the President will schedule and work with legislation and policy for the rest of the year?\nIf we tried to do this today, could we go back and re-read all of the State of the Unions and apply custom algorithms to help determine the sentiment behind the speeches? This is no longer a dream, but a reality. We can use IBM Bluemix to create an app that will pull in the speeches and leverage the IBM Watson User Modeling Service to analyze the speeches.\nWouldn’t it be interesting if we could compare the speeches from previous State of the Union addresses and compare the underlying sentiment behind them? Today we can, and it is pretty easy. MSNBC published How a supercomputer sees the State of the Union explaining how they used IBM Watson to do this. Let’s take it a step further, let’s build our app in about 5 minutes, and try it ourselves!\nThe biggest takeaway? This year’s State of the Union was surprisingly on-trend with the patterns established by previous speeches.Sam Petulla and Mina Liu – MSNBC So let’s dig into how we could do this.\nLet’s Build it! The goal at the end of these couple steps is to have our own Node.js app that uses the User Modeling Service to analyze the 2015 State of the Union.\nSo first we need to sign up for Bluemix if you don’t have an account.\nOnce we have logged in visit the Catalog and at the top under Boilerplates let’s click on UserModeling Node.js, or go directly here.\nOn the right hand side we just need to give our app a name. This will be the URL we will access our app at. Note, it needs to be unique, for my app I chose sotu-jbs, you can choose anything you want.\nClick Create. What is happening behind the scenes is Bluemix is spinning up a Node.js starter app that will allow you to analyze the state of the union address with Watson. Pretty cool huh?\nBluemix will take you to a dashboard and after a little bit it will show you that your app is up and running. To access our app, click the URL near the top of the dashboard under the name of our app.\nNow the hard bit, we need to grab the full text of the speech. This year was the first time the White House put out the full text of the speech, it is available on CNN. I have also made the full text available here. Copy this text.\nGo back to your app you created that just opened up. It should show something like the following. We want to clear the text and paste the full contents of the State of the Union.\nClick \u0026ldquo;Analyze\u0026rdquo;.\nThat’s it. You should have some output like the following. With Bluemix and Watson we were just able to analyze the sentiment/personality of the President in the 2015 State of the Union.\nPersonality with percentages:\nPersonality Visualization:\nWrap up So let’s go over what we did, in a matter of less than 5 minutes we spun up a Node.js app, connected it to Watson and analyzed the State of the Union. What Bluemix does for us is gives us a platform to run our apps and connects super cool and powerful services such as Watson to our apps in a matter of seconds. In the image below, we can see our app running and that is connected to Watson.\nIf you want to give this a try without deploying an app head over to the User Modeling Demo in Bluemix and paste in your text.\nLearn More If you want to learn more about other Bluemix services and Watson services go to the following links.\nBluemix Solutions\nBluemix Services\nWatson Services in Bluemix\nWatson Developer Cloud – User Modeling\n","date":"2015-01-21T09:45:24-05:00","image":"https://www.jeffsloyer.io/post/how-watson-and-bluemix-see-the-state-of-the-union/1USIIGtkypiwhO6W4o8cwIw_hu_d8fb5623594c47a3.jpeg","permalink":"https://www.jeffsloyer.io/post/how-watson-and-bluemix-see-the-state-of-the-union/","title":"How Watson and Bluemix see the State of the Union"},{"content":"Monolith apps are no more. The age of the monolith is over. It wasn’t that long ago that companies and developers (myself included) were deploying one giant app that did everything. The app would serve all your static files, front-end HTML and CSS and Javascript, act as your REST API, serve as your data persistance tier, handles sessions, handle logins, and do security for your app. The list could keep going on and on. As the age of the code base progresses it gets more and more complicated and tangled and if a new feature needs to be developed or an old piece of code needs to be modified it takes a cross functional team of many different people to make it happen.\nFirst we are going to talk about how a monolith app works, some of the positives and negatives and then we will talk about how things work in an app utilizing microserivces and the positivities and negatives associated with it.\nWhat is a Monolith? In a traditional monolith app you would have your basic three tier app consisting of a persistence layer, middleware tier/business logic, and front end code. The advantage of this is there is just one application to manage and scale. However the downside is that any change to any of the three tiers it requires cranking up the giant distributed team and pushing a new release. For example, if Dave a front-end dev wanted and he wanted to change the color of a button, it would require the whole app to built, tested, and re-deployed for a tiny change.\nThis is quite wasteful over everyone’s time, dev’s from the persistence layer, business logic team, and front end team need to be involved. This involves cutting a new release, running it through whatever QA/test phases there is and pushing it to production and hoping that nothing else got introduced or anyone else regressed some features.\nAdditionally, by having a monolith app the code base can become quite large and incredibly complex to maintain. This is compounded exponentially as the age of an app grows. Eventually, there is so much tangled and twisted code its hard to understand how things link together and work. This is one of the hidden costs of a monolith app.\nMicroservice Advantages A microservice can be defined simply as \u0026ldquo;fine grained SOA\u0026rdquo; – Adrian Cockcroft, Netflix. In a longer description it can be thought of a set of small services with known functionality communicating over a common lightweight API, either HTTP REST API’s or more recently a lightweight messaging protocol (more on this later).\n\"Fine grained SOA\" Adrian Cockcroft, Netflix Microservices provide a huge advantage for the case we talked about earlier where Dave our front-end dev wants to change the color of a button, no longer does the giant dev machine need to be involved. Instead the UI layer is a separate service and changes can be made independent from other parts of the application. The UI team can crank out as many releases as their heart desires.\n2 Pizza Teams We aren’t talking about skimping on our employees and not feeding them enough at work, but we are instead talking about the size of the team. Amazon first coined this term back in 2011. It has been written about extensively and in such publications as the Wall Street Journal. Basically what it boils down to is having each team small enough that you can feed them with 2 pizza’s. So you might be asking what the importance of this is, let’s use our example of our front-end dev Dave again. By Dave having a small team they can organize themselves efficiently and deliver functionality on their own instead of being tied to a giant release of the application. A team doesn’t have to multiple people, it can actually be a team of just 1 but be sure to never violate the 2 pizza team rule though.\nI Wanna Go Fast (It’s All About Speed) As popularized by Talladega Nights, speed is king. Who doesn’t want to go fast? If you answered no to that you are probably going to get beaten by your competition and be left in the dust. As the world is being flattened there is constantly new competition every day and dev team’s have to constantly be delivering to keep their product and company relevant.\nSo back to our example of Dave our front-end dev again. Since Dave’s team has their own UI service they can constantly deliver changes and new features without having to wait for other team’s to deliver functionality. Dave’s team can even deliver new UI code that is gated on some business logic code by using feature flags and A/B testing to selectively enable code and test new code out. This allows Dave’s team to try out new ideas and if they don’t work they fail fast and pivot and change course. By doing this Dave’s product and company stay relevant.\nAgain as Ricky Bobby from Talladega Nights would say, \u0026ldquo;if you aint first you’re last.\u0026rdquo; When I saw the movie my mind obviously just went to car racing and sports but it can be extended to the IT industry as well. If you aren’t first you probably aren’t relevant and someone else is beating you to market. Eventually you could go out of business.\nDevOps DevOps DevOps \u0026ldquo;To make error is human. To propagate error to all server in automatic way is #devops.\u0026rdquo; – DevOps Borat. This quote sums up why DevOps is important. With each service being completely different architecture wise and language it is in it would be near impossible for a central \u0026ldquo;ops\u0026rdquo; team to manage all the apps. Instead in microservices world each team is responsible for their own app. You might be thinking that having dev’s manage a production service is bad and they won’t be responsive. You are wrong, multiple companies have been doing this for years and it actually creates a sense of empowerment in the dev team. Dev’s don’t want a call at 3am in the morning notifying them that their service is down. In turn dev’s start taking more pride in their work and start thinking about decisions they make that will affect the availability of their service. It creates a new mindset for people.\nLet the Dev’s rule Continuing on from above empowering dev’s is super important. As a developer feels empowered they will make better decisions for their service they work on and thus end up making better decisions for the company. When someone feels empowered they are putting their stamp of approval behind a product or feature and basically signing it with their name, code to them is a craft.\nBy embracing microservices and the de-centralized architecture it allows dev’s to innovate and come up with cool ideas and test them out. If they don’t work that is ok, keep innovating and moving forward. I am a photographer and in college someone once told me for every 10 pictures you take you will only get one good one. The same can be said here as well, try, test, measure (repeat). Obviously there is some science and planning put into this but the point is creating an environment to foster innovation.\nDesign for Failure When using microservices each service should be able to stand on its own and run by itself. If it has outside dependencies it isn’t really a microservice. Netflix is a prime example of this. For example, if a service goes down that generates recommendations the whole site doesn’t break. Other services keep functioning without the broken service. In some cases, other services will know how to operate without the broken service. Feature degradation or local caching can be used to prevent a break in the user experience.\nThis is designing for failure. In the monolith world (which remember no longer exists) we would design and develop for the happy path and really never for the sad path. By having a service based architecture we need to design and develop for the failure cases. Some guy digging in his front yard could cut a piece of fiber and bring our monolith app to the ground. By designing for a service not being there and allowing the product to continue to function is at utmost important. In the monolith app dev’s sometimes would not think this way because everything is self contained by in a decentralized architecture you are forced to think about the failure case and how to handle it in a graceful way that doesn’t affect the user’s experience too much.\nImmutable Code Part of this thought of designing for failure is having immutable code. When introducing new code you MUST not affect the functionality of previous code. In a product that has a UI this is a little harder to do but can be done with feature flags and A/B testing but with an API based service changing the inputs and outputs of a service is a big no-no. If you absolutely must do this at least have a deprecation period of N+2 or 3 to give customers and consumers of your service some advanced warning that changes are coming. Ideally you wouldn’t deprecate an API, just revision your API, for example if you are using HTTP REST API’s just use /api/v1.0/ and for your next version /api/v1.1/ as a prefix.\nReal world Microservices architecture In the real world we would probably have a database, some business logic service (probably multiple of these), a UI service, our basic three tier app but this time disjoint from each other. See below. The \u0026ldquo;glue\u0026rdquo; between the services is supposed to be something light-weight, you can use HTTP REST API’s but more recently there has been a move to a messaging based \u0026ldquo;glue\u0026rdquo;. In particular like MQTT or AMQP. This is great as it allows a service to be a \u0026ldquo;worker\u0026rdquo; or a client of another service, or in queuing terms, producers and consumers.\nHow to use Bluemix to create Microservices To demonstrate this real world example let’s talk about how this would work in Bluemix. In Bluemix we can create a bunch of services, in case they will be in Node.js and the \u0026ldquo;glue\u0026rdquo; between our services will be MQLight. An important point we should talk about here is the notion of producer/consumer (pub/sub) vs round-robin queuing.\nFor our example let’s say we have a service that is scaled out to 5 nodes (we must be really popular). Each of these nodes is a worker for some business process, in this case let’s say sending a registration email. When someone sign’s up for our site we want to send them a registration email, we don’t want each of the 5 nodes of our service emailing the person. I would probably walk away from something if I got 5 duplicate registration emails. In this case we want round-robin queuing.\nHowever on the converse side there is cases where we want producer/consumer (pub/sub queuing). This effectively means all 5 nodes of a service will receive the same message and respond. Let’s say we have a UI service that is the front-end for a real time chat service. If our application is scaled out to 5 nodes how can we properly propagate chat messages to all the connected clients. The answer is allowing each front-end service to receive the same message to relay to all the clients.\nWhen architecting your microservices you need to keep queuing in mind and how clients and services communicate with each other. Make sure you choose a queuing technology that supports your desired behavior of pub/sub or round-robin.\nSo where does this leave us in Bluemix? MQLight, with MQLight you can easily do pub/sub and round-robin with the same service provider. This is great because as the developer I don’t have to use two different messaging providers.\nExample App in Bluemix So let’s build something to demonstrate all of this. The example app we will be building contains a front-end service that allows users to enter text and another service that will convert it to upper case. While this is not a real world example it demonstrates microservices using backend workers.\nA real world example might be an image processing app that applies a sexy filter to an image it and then uploads it to Instagram. If we did this we could break this up into three services. A web service that accepts an image over http(s), our sexy filter engine (maybe imagemagick), then a service that uploads the image to our social media network of choice.\nSo back to our example app of converting text to uppercase. The UI is below, our UI doesn’t lock when we submit data and we can keep using it. As results are finished processing in our \u0026ldquo;text uppercase\u0026rdquo; service, results are delivered real time to our front-end service.\nTo make this seem more world the example code introduces some timeouts/waits to make it seem like some backend processing is going on in a microservice. To get this running follow the following steps.\n1 2 3 git clone https://hub.jazz.net/git/ibmmq/mqlight-worker-offload-sample-node cf create-service MQLight standard MQLight-sampleservice cf push What the above does is checkout some example code that contains a front-end service and a back-end service that does our \u0026ldquo;text uppercasing\u0026rdquo; and creates a QLight to provide the messaging between our two services.\nOnce the cf push command is done running (it might take a bit) we should see something like the following saying our apps are up.\nText processing service:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Showing health and status for app MQL.sample.node.backend in org jbsloyer@us.ibm.com / space demos as jbsloyer@us.ibm.com... OK requested state: started instances: 2/2 usage: 256M x 2 instances urls: last uploaded: Mon Jan 19 18:52:05 +0000 2015 state since cpu memory disk #0 running 2015-01-19 01:53:08 PM 0.0% 11.8M of 256M 75.8M of 1G #1 running 2015-01-19 01:53:05 PM 0.0% 11.5M of 256M 75.8M of 1G Front-end service: Showing health and status for app MQL.sample.node.frontend in org jbsloyer@us.ibm.com / space demos as jbsloyer@us.ibm.com... OK requested state: started instances: 1/1 usage: 512M x 1 instances urls: mqlightsample-node-undeputed-trierarch.mybluemix.net last uploaded: Mon Jan 19 18:53:16 +0000 2015 state since cpu memory disk #0 running 2015-01-19 01:54:20 PM 0.0% 24.3M of 512M 78.7M of 1G So let’s checkout the app, I have recorded a short video of it working. If you notice the text service is simulating things like a real world service might respond with results coming back as they finish being processed.\nStay Tuned!!! There will be some real world examples coming on how to use microservices in Bluemix since now we have a foundation on what microserivces are. Please stay tuned and follow me on Twitter at @jsloyer for some real world apps!\nWebcast playback The replay of the webcast is available at here.\n","date":"2015-01-19T09:34:18-05:00","image":"https://www.jeffsloyer.io/post/microservices-in-bluemix/two-pizza_hu_f8e3d05325e3ff0d.jpg","permalink":"https://www.jeffsloyer.io/post/microservices-in-bluemix/","title":"Microservices in Bluemix"},{"content":"Etherpad Lite is an awesome online collaboration platform. Multiple open source projects use it for collaboration. One of the most notable ones is the Openstack Project Openstack Etherpad. To help you navigate the setup, this post provides step-by-step instructions to get things running. You may have read that Etherpad is complicated to install in a PaaS and there really isn’t a comprehensive quick start guide for running Etherpad-lite in Cloud Foundry. No worries, here is one!\nLogin/Register for Bluemix The first step is creating a Node.js app in Bluemix. Let’s login to Bluemix, open a web browser and visit Bluemix and click LOG IN. If you don’t have an account click, SIGN UP. Since Etherpad-Lite is built using Node.js, we want to start with an empty Node.js app in Bluemix. We will do this from the command line.\nIf you already have the CLI command line executable, you can skip this step. If you don’t have it, follow the steps from the Bluemix docs on how to install the command line for your platform and how to set it up. Once you get things setup you should be able to run cf s and get the following output:\n[01:30 PM] jsloyer@jeffs-mbp [blah]\u0026gt;cf s cf domains Getting domains in org jbsloyer@us.ibm.com as ... name status mybluemix.net shared Your output will be slightly different (this is ok). This was just a check to make sure things are setup correctly. If you are getting an auth error or error that you aren’t pointing to Cloud Foundry, refer back to the docs, reply to this post, or post a question to Stackoverflow for help.\nUpload Etherpad-Lite Code to Bluemix OK, next we need to upload the Etherpad-Lite code to Bluemix. The version of Etherpad-Lite is a forked version of the Etherpad code that has made things easy for us with Cloud Foundry. So head on over to the releases page for etherpad-lite-cf. Choose the latest, as of this writing it was version 1.4.1. Download the etherpad-lite-cf.zip file. We need to extract this file to a new folder—do not extract it in the folder it is sitting in. For example, I extracted it into an empty folder called blah. Make sure you do not have the zip file you downloaded in the newly created folder, it should just contain the extracted files:\n[10:50 AM] jsloyer@jeffs-mbp [blah]\u0026gt;pwd /Users/jsloyer/Downloads/blah [10:50 AM] jsloyer@jeffs-mbp [blah]\u0026gt;ls CHANGELOG.md Procfile node_modules src var CONTRIBUTING.md README.md package.json start.bat LICENSE bin settings.json tests Makefile doc settings.json.template tools The next step is pushing the app to Bluemix. Run the following command, replacing yourappname with a unique name for your app. This name will also be the url to your app as well. If you get an error mentioning the host is taken, just choose a different name.\n1 cf push yourappname -m 512M -b https://github.com/cloudfoundry/nodejs-buildpack.git The above is saying we are giving our app 512MB of memory and calling out a specific buildpack to use (in this case Node.js). This step will take awhile but eventually you should get the following output.\n0 of 1 instances running, 1 starting 0 of 1 instances running, 1 starting 0 of 1 instances running, 1 starting 1 of 1 instances running App started Showing health and status for app jbs-etherpad3 in org jbsloyer@us.ibm.com / space demos as ... OK requested state: started instances: 1/1 usage: 512M x 1 instances urls: jbs-etherpad3.mybluemix.net state since cpu memory disk #0 running 2015-01-13 10:36:32 AM 0.0% 87.2M of 512M 242.1M of 1G If you visit the url from above, Etherpad will be functional, however it is using a built-in database and this isn’t what we want. We want to back in with MySQL.\nCreate and bind a database to our app Next, we need to create a service to allow Etherpad to connect to our database. To do that, let’s go back to the Bluemix UI. In the top click on Dashboard, you should see the app you created. Let’s go ahead and click on it.\nTo add the service Bluemix will provision and bind a service to our app for us. Click \u0026ldquo;Add A Service\u0026rdquo; and scroll down to data management. We want ClearDB for this app. Click on ClearDB. ClearDB is a hosted version of MySQL. Everything on the right should be pre-populated so let’s just click \u0026ldquo;Create\u0026rdquo;. If things are not pre-populated, choose the appropriate app, the one we just created.\nIt will ask if you want to restage the app, that is fine, so click RESTAGE.\nConfigure the app with ClearDB (MySQL) To switch the app over to MySQL, we need to edit the settings.json for the app and then re-upload the app to Bluemix. You will need to replace the value DATABASE on line 9 with the name of your ClearDB service. To get this info, let’s go back to the Bluemix UI and our app. If you click on \u0026ldquo;Show Credentials\u0026rdquo;, it will give you the name of your ClearDB service, copy this.\nCopy the name, in this example it is \u0026ldquo;ClearDB MySQL Database-hu\u0026rdquo;, without quotes. I have highlighted below what you need to copy, don’t copy the quotes. I have hidden my connection info to my database so my database can’t be hacked.\nOpen up settings.json with your favorite text editor and on line 9 replace DATABASE with the name of your ClearDB service that we copied from above. Save the file. Here is my line 9:\n1 \u0026#34;dbService\u0026#34;: \u0026#34;ClearDB MySQL Database-hu\u0026#34;, The last step is re-pushing our app to Bluemix since we made a change to it. To do this we need to use the push command we used above:\n1 cf push yourappname -m 512M -b https://github.com/cloudfoundry/nodejs-buildpack.git Eventually it should show us that our app is running, my output is below:\n0 of 1 instances running, 1 starting 0 of 1 instances running, 1 starting 0 of 1 instances running, 1 starting 1 of 1 instances running App started Showing health and status for app jbs-etherpad3 in org jbsloyer@us.ibm.com / space demos as ... OK requested state: started instances: 1/1 usage: 512M x 1 instances urls: jbs-etherpad3.mybluemix.net state since cpu memory disk #0 running 2015-01-13 10:36:32 AM 0.0% 87.2M of 512M 242.1M of 1G So if we visit the url it gave us, Etherpad should be up and running. If you run into issues please post a comment here or post to Stackoverflow.\nSSL Bluemix provides SSL out of the box for your app. If your app is running at http://jbs-etherpad3.mybluemix.net you are given SSL for free. To use SSL, just access your app over https, for my example it would be https://jbs-etherpad3.mybluemix.net. If you want to use SSL with your own domain name and certificate, you can do this also! See SSL Certificates and Bluemix Custom Domains on how to do it.\nFor more info about SSL in for free in Bluemix check out the following video.\nCaveats The biggest issue to me is that this deployment of Etherpad only allows 1 instance. While this works for development and testing, it is not suitable for production. This is a limitation right now of Etherpad in the way it uses socket.io and sessions. If you need more capacity, just bump up your RAM for your app. Instructions adapted from these references https://github.com/cloudfoundry-community/etherpad-lite-cf#using-database-from-user-provided-service\nhttp://arthurh.fr/blog-Install-etherpad-lite-with-cloudfoundry\n","date":"2015-01-03T22:19:30-05:00","permalink":"https://www.jeffsloyer.io/post/etherpad-in-cloud-foundry-quick-start-guide/","title":"Etherpad in Cloud Foundry – Quick Start Guide"},{"content":"Hey Yall!\nWe are back at it again with some demos!!!\nDid you ever wonder if you and your favorite celebrity would be compatible if you met?? I sure do! Or did you ever wonder how you could become a better leader, I sure do. Today you would have to go Google the person and analyze posts and articles about them and be a personality expert to see if you have personality traits in common.\nGone are those days now!\nEnter FriendMe! Your trusted personality comparison using IBM Watson. The answer to the above questions are easy now. For example, if I compared myself to the IBM Design Twitter account, I can see my personality is very much alike with the IBM Design team. Thats good news for me because I never considered myself a designer… For the leadership, personal, and professional case, Jerry Cuomo is a very successful leader at IBM. I can see that myself and Jerry share 5 out of the top 5 personality traits in common. In my career development I can see I need to develop myself more as a transformational leader.\nLastly, I am going to do one more comparison, between myself and Blake McGregor (a product manager for Bluemix).\nSo let’s jump right into it.\nThis app was written in about 6 hours, its built using obviously IBM Bluemix, Node.JS, Angular.JS, Bootstrap, JQuery, IBM Watson, Cloudant, and Twilio.\nIf you went to the link above, here it is again. You can actually text the app. If you text the app two Twitter handles it will tell you the compatibility between two people.\nSo the source code is available on Github.\nFirst, we are going to walk through on how to deploy this app and get it working in Bluemix. Secondly, we are going to walk through how to use the command line to deploy this app as well.\nIf you haven’t already sign up for a Bluemix account. Once you have done that head over to jazzhub.com. Login there with the username and password you created from your Bluemix account. If you haven’t logged in yet to jazzhub it will ask you to create an id. For example if my email is jsmith@co.com, I would create a username of jsmith.\nFirst, let’s open a web browser and goto https://github.com/IBM-bluemix/friendme. Since we already created an account or logged in jazzhub above we should be logged in. On the right hand side near the top there should be a big button that says \u0026ldquo;Fork Project\u0026rdquo;. Let’s click that.\nLet’s go ahead and enter a project name, for example friendme, you can name it anything you want though. Next place a check mark next to \u0026ldquo;Make it Private\u0026rdquo;, more on this later… Next make sure an organization and space is shown, it should should your email address as the organization and the space should be dev. Lastly, click \u0026ldquo;Save\u0026rdquo;.\nNext we need to create the app in Bluemix and setup some services. So in a new browser window navigate to http://bluemix.net. In the top right click login.\nOnce you login click on catalog and find SDK for Node.JS. Go ahead and click on it.\nType in a name for your app, this will also be the URL for your app, remember this as we will need it later… Then click \u0026ldquo;Create\u0026rdquo;.\nBehind the scenes Bluemix is spinning up a container for our app, setting up SSL, and setting up load balancing. In a traditional IaaS, you would have to do all this manually and it can take hours or days…\nNext, we need to add some services to our app. We need Watson and Cloudant. Let’s do Watson first. The Watson service that we want is User Modeling. It will analyze text and determine someone’s personality. So to do this let’s click \u0026ldquo;Add A Service\u0026rdquo;.\nLet’s go to the Watson section and click on \u0026ldquo;User Modeling\u0026rdquo;.\nIt will bring up a dialog asking us to bind the service to our app, on the right hand side, click \u0026ldquo;Create\u0026rdquo;.\nIt will ask us if we want to restage the app, go ahead and click ok. What this means is it needs to bind the service to the app and to do this it needs to restart it.\nNext, we need to create a database, to do this let’s click on the Cloudant tile.\nThen let’s click on the launch button.\nNext we need to create a database, click on \u0026ldquo;Add New Database\u0026rdquo; in the top right.\nThen enter a name for the database, let’s use friendme, if you use something else we will have to edit the code… Go ahead and click \u0026ldquo;Create\u0026rdquo;.\nWe can close out of Cloudant now.\nSo, since we are making API calls to Twilio and Twitter we need to register for API key’s.\nLet’s do Twitter first, head on over to http://apps.twitter.com and login with your Twitter username and password.\nIn the top right let’s click on \u0026ldquo;Create New App\u0026rdquo;. Type in a name and description for the app, the URL actually doesn’t matter but let’s type in something real. Remember above the name you created for your app in Bluemix, let’s type that in. For example http://friendme.mybluemix.net. Replace friendme with the name of your app.\nClick on the \u0026ldquo;Keys and Access Tokens\u0026rdquo; tab. Under Access Tokens click \u0026ldquo;Create my access token\u0026rdquo;. Leave this tab open, we will need these API’s keys in a bit…\nNext we need a Twilio phone number if you would like to be able to text your app. If you don’t want to be able to text the app skip this section, you can use the UI of the app to interact with it. Head on over to https://www.twilio.com/try-twilio and create an account. If you already have an account go ahead and goto https://www.twilio.com/user/account/phone-numbers/incoming or if you just created an account go there as well.\nWe need to buy a number, to do this click on \u0026ldquo;Buy Number\u0026rdquo; in the top right. Make sure the number has texting capabilities.\nTry to find one of the cheaper ones, the cheapest you can find is $1/month, not bad…\nSo once we buy the number we will need our API key’s. They can be found at https://www.twilio.com/user/account/settings. Leave this tab open like we did for Twitter, we will come back to this…\nOk so finally time to deploy our app. To do this switch back to Jazzhub, click the \u0026ldquo;Build \u0026amp; Deploy\u0026rdquo; button in the top right.\nGo ahead and click on \u0026ldquo;Advanced\u0026rdquo; to turn on deployments.\nClick on \u0026ldquo;add a builder\u0026rdquo;.\nFor builder type choose \u0026ldquo;Shell Script\u0026rdquo;.\nFor the build script text area enter the following.\n#!/bin/bash echo \u0026quot;do nothing\u0026quot; Since it is node we really don’t need a build here… If this wasn’t a demo and real app we would probably run some unit tests and do some linting here…\nClick on Save.\nNext we need to set up the deployment. Click on \u0026ldquo;add a stage\u0026rdquo;.\nMake sure the app name matches the app name we created in Bluemix.\nLast thing we need to do is modify the build script. This is the only really confusing bit, you need to make sure you set this up correct or the app won’t work…\nWhen you first click on \u0026ldquo;add a stage\u0026rdquo; it will look like the following\u0026hellip;\nThe script will look like the following.\n1 2 3 4 5 6 7 8 9 cf push \u0026#34;${CF_APP}\u0026#34; -n \u0026#34;${CF_APP}-${CF_SPACE}\u0026#34; # View logs EXIT_CODE=$? if [ $EXIT_CODE -ne 0 ] then cf logs \u0026#34;${CF_APP}\u0026#34; --recent exit $EXIT_CODE fi We will need to update it to the following.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 cf set-env \u0026#34;${CF_APP}\u0026#34; TWILIO_PHONENUMBER \u0026#34;replaceme\u0026#34; cf set-env \u0026#34;${CF_APP}\u0026#34; TWILIO_SID \u0026#34;replaceme\u0026#34; cf set-env \u0026#34;${CF_APP}\u0026#34; TWILIO_TOKEN \u0026#34;replaceme\u0026#34; cf set-env \u0026#34;${CF_APP}\u0026#34; TWITTER_ACCESSTOKEN_KEY \u0026#34;replaceme\u0026#34; cf set-env \u0026#34;${CF_APP}\u0026#34; TWITTER_ACCESSTOKEN_SECRET \u0026#34;replaceme\u0026#34; cf set-env \u0026#34;${CF_APP}\u0026#34; TWITTER_CONSUMER_KEY \u0026#34;replaceme\u0026#34; cf set-env \u0026#34;${CF_APP}\u0026#34; TWITTER_CONSUMER_SECRET \u0026#34;replaceme\u0026#34; cf push \u0026#34;${CF_APP}\u0026#34; -c \u0026#34;node lib/app.js\u0026#34; # View logs EXIT_CODE=$? if [ $EXIT_CODE -ne 0 ] then cf logs \u0026#34;${CF_APP}\u0026#34; --recent exit $EXIT_CODE fi For each of these values we need to substitute in the the correct values from the tab’s we kept open earlier from Twitter and Twilio.\nIf you remember earlier we made the project private, this was to prevent other people from seeing our secret access key’s. DevOps Service will be rolling out a new over the coming weeks where you can find information for a public project.\nOnce you replace the values go ahead and click \u0026ldquo;Save\u0026rdquo;.\nLast thing to do is click \u0026ldquo;Request Build\u0026rdquo;. That should successfully complete and that will trigger a deployment of your app.\nYou can see the deployment is being performed by the following screen shot.\nOnce the deployment finishes you can click the link (name of your app) to your app to use it!\nPlease reach out to me on Twitter (@jsloyer) if you have any issues or post a comment below.\n","date":"2014-11-24T22:06:16-05:00","image":"https://www.jeffsloyer.io/post/twitter-personality-comparisons-using-watson/personality_hu_39dba5c5f7fdf727.jpg","permalink":"https://www.jeffsloyer.io/post/twitter-personality-comparisons-using-watson/","title":"Twitter Personality Comparisons Using Watson"},{"content":"Backed by popular demand this is a continuation of the post Building a Java EE app on IBM Bluemix Using Watson and Cloudant.\nThis post will detail how to build and deploy the app using IBM DevOps Services.\nThere is a bit of magic behind this, its called \u0026ldquo;The Deploy to Bluemix Button\u0026rdquo;\u0026hellip;\nClicking the magic button below will setup the app using IBM DevOps services and deploy the whole application for you.\nSo let\u0026rsquo;s talk about what this magic button does. The button is actually just a shortcut to setting up the deployment pipeline for you. What it does behind the covers is the following.\nClones the git project Configures the devops pipeline Triggers the pipeline Compiles the .war file Deploys the application To Bluemix Isn\u0026rsquo;t that pretty cool? Well what are you waiting for, click the button above!\n","date":"2014-11-24T21:54:23-05:00","image":"https://www.jeffsloyer.io/post/deploying-a-watson-and-cloudant-app-with-devops-services/devops_hu_5f071d6607bcfbaa.jpg","permalink":"https://www.jeffsloyer.io/post/deploying-a-watson-and-cloudant-app-with-devops-services/","title":"Deploying a Watson and Cloudant App with DevOps Services"},{"content":"While IBM is rapidly bringing new services and capabilities into Bluemix, one of the reasons our customers are so interested in Bluemix is because they can use our platform and services in conjunction with many other open source and third party APIs and services. The ability to easily access and integrate this combination of technology is one of the biggest values for any developer looking to build applications on Bluemix.\nAs our enterprise clients move toward cloud and use Bluemix as a means to do so, the platform also offers 3rd parties a great opportunity to reach enterprise development tools with the tools and services you are working on. As you can tell from the last below, some great partners have already joined.\nTwilio\nBlazeMeter\nLoad Impact\nNew Relic\nCloudAMQP\nPitney Bowes\nMemcached Cloud\nSendGrid\nUStream\nClearDB\nElephantSQL\nMongoLab\nRedis Cloud\nThis list is constantly changing, for an up to date list please visit the Bluemix Catalog. If you would like your company or project to be available as a service in Bluemix check out the IBM Business Partner Guide. We would love to help you get your service into Bluemix!\n","date":"2014-11-19T21:42:10-05:00","image":"https://www.jeffsloyer.io/post/onboarding-guide-for-bluemix-for-third-parties/guide_hu_5a0319f2b6147e7b.jpg","permalink":"https://www.jeffsloyer.io/post/onboarding-guide-for-bluemix-for-third-parties/","title":"Onboarding Guide for Bluemix for Third Parties"},{"content":"Hey Y’all!\nJeff here again and something I am really excited about is Watson is now available for anyone to use in Bluemix!\nToday we are going to be building an example app using Java, Cloudant, and Watson.\nOk let’s talk through what this app is going to do before we build it.\nMeet Ivy (hello!)\nShe’s a talent manager at a growing tech startup.\nShe’s looking for a new hire that would be a good fit on her team but the company is so popular that she has a huge inventory of resumes to sort through. She’s looking for tools to help her, and tools beyond just simple tag filters.\nWith Watson services she can also start to solve for a problem like, \u0026ldquo;I’m looking for another developer like \u0026ldquo;[insert cool employee].\u0026rdquo;\nSo in this case, the application can issue queries such as,\nFind me a Developer like Craig Smith.Then search through all possible candidate and return a ranked list of candidates sorted by highest-to-lowest percentage of personality resemblance. From here, searches can be refined by including technical skills. Find me a Developer like Craig Smith, and knows Java, C and Python.\n\u0026ndash; Ivy (HR Manager)\nMake sense??\nOk let’s jump right in.\nPre-req\u0026rsquo;s First thing you need to do is clone the github project with some starter code.\n1 git clone https://github.com/IBM-Bluemix/talent-manager.git Or download a zip file if you don’t have git installed.\nNext we need to complete a couple pre-req steps.\nDownload Eclipse EE Download and install Java 1.7 JDK Download and install the Cloud Foundry CLI Sign up for a FREE IBM Bluemix account if you don’t have one yet Ok once we have all that setup we can start creating our app.\nCreate the application First we need to sign into Bluemix, so open your browser and head on over to Bluemix. We need to login. Up at the top lets go ahead and click on Catalog.\nScroll down a little and click on Liberty\nOn the right hand side we need to give our app a name. Please note that this name must be unique. Also remember this name as we will need it later…\nClick create.\nBluemix will start deploying our app and Bluemix will start our app.\nSo next we need to add Cloudant and Watson to our app!\nSo do you that make sure you are in the dashboard and have your app open like the screencap below. We will then click the \u0026ldquo;Add A Service\u0026rdquo; button.\nFirst let’s add Watson. Scroll down until you find the \u0026ldquo;User Modeling\u0026rdquo; Service. Go ahead and click that.\nAgain, all we have to do is click \u0026ldquo;Create\u0026rdquo; on the right hand side.\nBluemix is going to ask us if we want to restage our app, we should click the \u0026ldquo;OK\u0026rdquo; button. What Bluemix is asking us here is since we made a change to our app, the app needs to be restarted to bind in Watson.\nNext, let’s click \u0026ldquo;Add A Service\u0026rdquo; again.\nThis time scroll down to the bottom and choose \u0026ldquo;Cloudant\u0026rdquo;.\nThen click \u0026ldquo;Create\u0026rdquo; on the right hand side.\nIt is going to ask us to restage our app again, go ahead and click \u0026ldquo;OK\u0026rdquo;.\nNow we have all our services added. Let’s go ahead and start getting some data imported.\nOn the dashboard for the app let’s go ahead and click on Cloudant.\nExplanation of Cloudant So let’s pause and explain what Cloudant is. Cloudant is a No-SQL database that is based on CouchDB. The big difference between a relationship database and No-SQL database is illustrated below. In the relationship database you have to have multiple tables to represent the data and have to use SQL and JOIN statements to get data from both tables. In a No-SQL database which is commonly referred to as a document store database you stores JSON documents/data (as illustrated on the left below).\nSo back to the demo\u0026hellip;\nEclipse Steps In Eclipse, right click on the project’s area on the left.\nUnder General click existing project into workspace and click next\nNext we want to find our project we downloaded from github. We need to browse to the directory where it is. Once you find the talent-manager folder, go one more level down into that into a folder called personafusion (as shown below). Click finish.\nNext, we need to make a couple code edits…\nIn src/com.ibm.personafusion/Config.java.\nLine 10 currently reads like below.\n1 public static final String CLOUDANT_NAME = \u0026#34;\u0026#34;; It needs to be changed to what is below. This is our Cloudant database name we created. If you used something other than \u0026ldquo;talent-manager here\u0026rdquo; type that in.\n1 public static final String CLOUDANT_NAME = \u0026#34;talent-manager\u0026#34;; Go ahead and save that file and close it.\nNext open src/com.ibm.personafusion/CloudantClient.java\nWe need to update our constructor from what is below.\n1 2 3 4 5 6 7 8 9 10 11 public CloudantClient() { this.httpClient = null; //TODO read env VCAP_SERVICES and parse it into JSON this.port = Config.CLOUDANT_PORT; this.host = \u0026#34;\u0026#34;; this.username = \u0026#34;\u0026#34;; this.password = \u0026#34;\u0026#34;; this.name = Config.CLOUDANT_NAME; this.dbc = this.createDBConnector(); To this.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 private JSONArray cloudant; private JSONObject cloudantInstance; private JSONObject cloudantCredentials; public CloudantClient() { this.httpClient = null; try { String VCAP_SERVICES = System.getenv(\u0026#34;VCAP_SERVICES\u0026#34;); JSONObject vcap; vcap = (JSONObject) JSONObject.parse(VCAP_SERVICES); cloudant = (JSONArray) vcap.get(\u0026#34;cloudantNoSQLDB\u0026#34;); cloudantInstance = (JSONObject) cloudant.get(0); cloudantCredentials = (JSONObject) cloudantInstance.get(\u0026#34;credentials\u0026#34;); } catch (IOException e) { e.printStackTrace(); } this.port = Config.CLOUDANT_PORT; this.host = (String) cloudantCredentials.get(\u0026#34;host\u0026#34;); this.username = (String) cloudantCredentials.get(\u0026#34;username\u0026#34;); this.password = (String) cloudantCredentials.get(\u0026#34;password\u0026#34;); this.name = Config.CLOUDANT_NAME; this.dbc = this.createDBConnector(); } If you notice we also added 3 global variables as well.\nNext we need to update the Watson code as well. This is located in src/com.ibm.personafusion/services/WatonUserModeler.java\nBefore:\n1 2 3 4 5 6 7 8 9 10 11 12 13 public WatsonUserModeller() { //TODO read env VCAP_SERVICES and parse it into JSON this.username = \u0026#34;\u0026#34;; this.password = \u0026#34;\u0026#34;; this.base_url = \u0026#34;\u0026#34;; this.profile_api = Config.WATSON_PROF_API; this.visual_api = Config.WATSON_VIZ_API; this.executor = Executor.newInstance().auth(username, password); if (this.executor == null) { System.err.println(\u0026#34;Authentication failed in WatsonUserModeller.\u0026#34;); } } After:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 private static JSONArray watson; private static JSONObject watsonInstance; private static JSONObject watsonCredentials; private Executor executor; public WatsonUserModeller() { try { String VCAP_SERVICES = System.getenv(\u0026#34;VCAP_SERVICES\u0026#34;); JSONObject vcap; vcap = (JSONObject) JSONObject.parse(VCAP_SERVICES); watson = (JSONArray) vcap.get(\u0026#34;user_modeling\u0026#34;); watsonInstance = (JSONObject) watson.get(0); watsonCredentials = (JSONObject) watsonInstance.get(\u0026#34;credentials\u0026#34;); } catch (IOException e) { e.printStackTrace(); } this.username = (String) watsonCredentials.get(\u0026#34;username\u0026#34;); this.password = (String) watsonCredentials.get(\u0026#34;password\u0026#34;); this.base_url = (String) watsonCredentials.get(\u0026#34;url\u0026#34;); this.profile_api = Config.WATSON_PROF_API; this.visual_api = Config.WATSON_VIZ_API; this.executor = Executor.newInstance().auth(username, password); if (this.executor == null) { System.err.println(\u0026#34;Authentication failed in WatsonUserModeller.\u0026#34;); } } Ok, so the app is basically done, we need to build our war file now, on the left side in Eclipse, open build.xml. On the right hand side right click build [default] and then \u0026ldquo;Run As\u0026rdquo; and then \u0026ldquo;Ant Build\u0026rdquo;. This will generate our WAR file for us that we will deploy.\nIn the bottom it should say \u0026ldquo;BUILD SUCESSFULL\u0026rdquo;.\nThe next and last step involves deploy your app to bluemix. This step requires the Cloud Foundry CLI to be installed (if you haven’t done this yet scroll back up the pre-req’s section above).\nIf you are on Windows open up the command prompt, if you are on a Mac or Linux open up the terminal.\nType the following.\n1 cf login -a https://api.ng.bluemix.net It will then ask for your username and password that you registered with for Bluemix. There are two important files in this directory.\nmanifest.yml webStarterApp.war We need to edit the manifest.yml file and then we can deploy the app. Open the file in your favorite text editor or you can use Eclipse as well. The contents of the file are below. There are two important lines in here, host and name. These values need to be unique and match the app we deployed earlier. In my case the app name is talent-manager-awesome, so my file would then become what is below.\nThis value comes from Bluemix, lets open the Bluemix dashboard in our web browser again. In the screenshot below we can just copy the name of the app and paste this into the manifest.yml file. So don’t copy my apps name exactly as it won’t work, it needs to be your app’s unique name.\nNow the final step we need to cd (change directory) in our command prompt or terminal to where the manifest.yml and webStarterApp.war are located. For me its located at /Users/jsloyer/Downloads/talent-manager-master/personafusion.\n1 2 cd /Users/jsloyer/Downloads/talent-manager-master/personafusion cf push The cf push command pushes our app to Bluemix, a bunch of text will fly bay saying its deploying and eventually it will say the app is starting and then it is up and running. Bluemix will give you a URL you can access your app at.\nVoila!!!! We created a Java web app using Cloudant and Watson on IBM Bluemix!\nSource Code: https://ibm.biz/talent-manager\nFeedback is welcome, please contact me on Twitter @jsloyer – http://twitter.com/jsloyer\nFor a video walkthrough of this demo please visit http://ibm.biz/talent-manager-demo or watch the video below!\nThis app was developed over the course of 48 hours at an internal hackathon. The developers and designers that worked on this are the following.\nEva XIAOHUI LUO MICHAEL J. YOUNG SEAN J. WELLECK BRIAN T. HAN MICHAEL POPLAVSKI ALAN XIA Jeff Sloyer ","date":"2014-10-14T22:36:53-05:00","image":"https://www.jeffsloyer.io/post/building-a-java-ee-app-on-ibm-bluemix-using-watson-and-cloudant/hiring_hu_28286bb059921430.png","permalink":"https://www.jeffsloyer.io/post/building-a-java-ee-app-on-ibm-bluemix-using-watson-and-cloudant/","title":"Building a Java EE app on IBM Bluemix Using Watson, Cloudant"},{"content":"In Cloud Foundry (the open source technology behind Bluemix), when you do a cf push, Cloud Foundry will actually stop your app and restart it with the new code that you just uploaded. This presents an issue for a production app or any app that is actually serving users. There is a shortcoming with the current DEA (the part in Cloud Foundry that runs your app) but the next version of the DEA (Diego) will help address this. In the meantime you can do a little scripting to get around this.\nThe basic flow is as follows:\nApp A is running (prod) Deploy App B Do some tests against App B Map prod route to App B Unmap prod route from App A Stop App A Delete App A Here is some starter shell code to do it:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # deploy.sh #!/bin/bash cf unmap-route blue-app mybluemix.net -n cf-blue-green # make the app unavailable to requests cf push blue-app # wait for the blue app to start while true; do RESP=`curl -sIL -w \u0026#34;%{http_code}\u0026#34; \u0026#34;blue-app.mybluemix.net\u0026#34; -o /dev/null` if [[ $RESP == \u0026#34;200\u0026#34; ]] then break else sleep 3 \u0026amp;amp;\u0026amp;amp; echo \u0026#34;Waiting for 200 response\u0026#34; fi done # make the blue app available to the router cf map-route blue-app mybluemix.net -n cf-blue-green # deploy to the green app cf unmap-route green-app mybluemix.net -n cf-blue-green cf push green-app cf app green-app cf map-route green-app mybluemix.net -n cf-blue-green ","date":"2014-08-18T22:10:32-05:00","image":"https://www.jeffsloyer.io/post/zero-downtime-deployments-with-bluemix/unplug_hu_5a7d5a25d79328e0.jpg","permalink":"https://www.jeffsloyer.io/post/zero-downtime-deployments-with-bluemix/","title":"Zero Downtime Deployments with Bluemix"},{"content":"Did you know in Bluemix you get inbound SSL for free? It is automatically turned on and enabled for every app. All you have to do is just access your app over https instead of http.\nDevelopers don’t need to implement SSL in their app, you just need to support HTTP and the Bluemix infrastructure will support HTTPS for you and do SSL offloading.\nAdditionally Bluemix supports the x-forwarded-proto header to allow developers to check with protocol requests are coming in over. I have pasted some example Node.JS middleware that you can check if the request is coming in over https or not.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 var middleware = module.exports, url = require(\u0026#34;url\u0026#34;); var HTTP = \u0026#34;http:\u0026#34;, HTTPS = \u0026#34;https:\u0026#34;; middleware.transportSecurity = function () { var applicationURL = config().appURL(), scheme = url.parse(applicationURL).protocol; function securityEnabled () { if (scheme !== HTTP \u0026amp;amp;\u0026amp;amp; scheme !== HTTPS) { throw new Error( \u0026#34;The application URL scheme must be \u0026#39;http\u0026#39; or \u0026#39;https\u0026#39;.\u0026#34; ); } return scheme === HTTPS; } function redirectURL (request) { return url.resolve(applicationURL, request.originalUrl); } if (securityEnabled()) { console.log(\u0026#34;Transport security is enabled.\u0026#34;); } return function (request, response, next) { // handling non-standard proxy headers ibm cf uses if(request.headers.protocol) { request.headers[\u0026#34;x-forwarded-proto\u0026#34;] = request.headers.protocol; } else if(request.headers.$wssc) { // The $wssc header is something that WebSphere inserts to pass the // proxied protocol to downstream applications request.headers[\u0026#34;x-forwarded-proto\u0026#34;] = request.headers.$wssc; } if (securityEnabled() \u0026amp;amp;\u0026amp;amp; !request.secure) { log.info(\u0026#34;Redirecting insecure request for\u0026#34;, request.originalUrl); response.redirect(301, redirectURL(request)); } else { next(); } }; }; 1 2 3 4 ... var middleware = require(\u0026#34;./middleware\u0026#34;); ... app.use(middleware.transportSecurity()); For more information check out the Bluemix SSL docs.\n","date":"2014-08-18T13:24:00-05:00","image":"https://www.jeffsloyer.io/post/inbound-ssl-in-bluemix/secure_hu_a802a666c6795576.jpg","permalink":"https://www.jeffsloyer.io/post/inbound-ssl-in-bluemix/","title":"Inbound Ssl in Bluemix"},{"content":"Kraken.JS is a new wonderful framework wrapper around Express for Node.JS. It includes things such as pre-canned security settings, templating, and internationalization. While Express in Node allows you to customize these type of things its not the most fun thing or exciting thing to do. While security is very important in your app why should you have to write redundant code for this. The answer is you do not have to anymore.\nWhile Express in Node allows you to customize these type of things its not the most fun thing or exciting thing to do. While security is very important in your app why should you have to write redundant code for this. The answer is you do not have to anymore. With Kraken.JS it will drastically cut the number of lines down in your Node app. I currently have an app right now where I am estimating if I converted it to Kraken.JS it would cut my code base by 33%. So let’s jump into Kraken.JS, the instructions below were based on Kraken’s documentation.\nStep 1, install Kraken if you do not already have it installed.\nsudo npm install -g generator-kraken Note: If \u0026ldquo;yo\u0026rdquo; yeoman is not installed, the above command will install it.\nCreate a basic project (follow the prompts on the screen)\nyo kraken Start your app\nnpm start If you notice the app started on 8000, with Bluemix and other PaaS’ you need to start your app on the port that the PaaS assigns you. To do this we need to modify the example app slightly. If you open up index.js down near the bottom you will see the following code snippet. …\n1 2 3 4 5 6 7 if (require.main === module) { kraken.create(app).listen(function (err) { if (err) { console.error(err.stack); } }); } The above code will automatically bind to port 8000, we need to allow it to bind to a port that Bluemix wants. Modify the code snippet to the following.\n1 2 3 4 5 6 7 if (require.main === module) { kraken.create(app).listen(process.env.VCAP_APP_PORT || 8000, function (err) { if (err) { console.error(err.stack); } }); } The whole source of this app is on Github here. If you want to pull the code do the following.\n1 git clone https://github.com/IBM-Bluemix/kraken-example.git ","date":"2014-04-17T13:24:00-05:00","image":"https://www.jeffsloyer.io/post/kraken-js-and-bluemix/kraken_hu_1ebcbaa150677489.jpg","permalink":"https://www.jeffsloyer.io/post/kraken-js-and-bluemix/","title":"Kraken.Js and Bluemix"}]